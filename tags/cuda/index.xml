<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cuda on Bikulov&#39;s blog</title>
    <link>https://bikulov.org/tags/cuda/</link>
    <description>Recent content in cuda on Bikulov&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ru</language>
    <copyright>Network Notes 2022</copyright>
    <lastBuildDate>Sat, 28 Feb 2015 08:54:00 +0300</lastBuildDate><atom:link href="https://bikulov.org/tags/cuda/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Install CUDA 6.5 on clean Ubuntu 14.04</title>
      <link>https://bikulov.org/blog/2015/02/28/install-cuda-6.5-on-clean-ubuntu-14.04/</link>
      <pubDate>Sat, 28 Feb 2015 08:54:00 +0300</pubDate>
      
      <guid>https://bikulov.org/blog/2015/02/28/install-cuda-6.5-on-clean-ubuntu-14.04/</guid>
      <description>Lately NVIDIA added repository for Ubuntu 12.04 and Ubuntu 14.04. Recently I hit problem with missing dependencies for libcheese-gtk23 and libcheese7 libraries while installing latest CUDA 6.5 on clean Ubuntu 14.04. Remedy to this can be found on askubuntu. So, the complete set of commands is below.
At first, add CUDA repository package:
wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_6.5-14_amd64.deb sudo dpkg -i cuda-repo-ubuntu1404_6.5-14_amd64.deb Now, install CUDA:
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get upgrade  # install nvidia driver sudo apt-get install nvidia-current # at this point you need to reboot computer  # remove broken packages, beware: some GUI parts of your system will be broken or removed sudo apt-get remove libcheese*  # install CUDA sudo apt-get install cuda  # restore broken GUI parts sudo apt-get install ubuntu-desktop By the way, libcheese is library for video and photo capturing, including enumeration of capturing devices.</description>
    </item>
    
    <item>
      <title>Example of CMake file for CUDA&#43;CPP code</title>
      <link>https://bikulov.org/blog/2013/12/24/example-of-cmake-file-for-cuda-cpp-code/</link>
      <pubDate>Tue, 24 Dec 2013 22:44:00 +0300</pubDate>
      
      <guid>https://bikulov.org/blog/2013/12/24/example-of-cmake-file-for-cuda-cpp-code/</guid>
      <description>Makefiles are quite straightforward and easy to write (in reasonable situations). But GNU Make is not crossplafrom. CMake is cross-platform, cross-application (it can generate projects for different IDEs and Makefile itself).
It also allows you to split source directory and directory with intermediate files and compiled binary. Now CMake natively supports CUDA.
Here is CMakeLists.txt example I use (simply place it next to your source files to try yourself):
CMAKE_MINIMUM_REQUIRED(VERSION 2.</description>
    </item>
    
    <item>
      <title>Using CUDA C&#43;&#43; functions in Python via `*.so` and ctypes</title>
      <link>https://bikulov.org/blog/2013/10/01/using-cuda-c-functions-in-python-via-.so-and-ctypes/</link>
      <pubDate>Tue, 01 Oct 2013 08:33:00 +0300</pubDate>
      
      <guid>https://bikulov.org/blog/2013/10/01/using-cuda-c-functions-in-python-via-.so-and-ctypes/</guid>
      <description>I&amp;rsquo;d like to show how to use HPC part written on C++ with CUDA in Python code. So, every heavy part may be done on GPU with CUDA, all gluing tasks (with beautiful matplotlib plots) are done on CPU with Python.
We will use shared object, compiled from C++ CUDA code in Python. The only uncertain part here is conversation of types from «high-level» Python ones to «low-level» C++ ones. We will write application for parallel calculation of elementwise sum for two arrays.</description>
    </item>
    
    <item>
      <title>CudaSafeCall application snippet</title>
      <link>https://bikulov.org/blog/2013/08/16/cudasafecall-application-snippet/</link>
      <pubDate>Fri, 16 Aug 2013 12:14:00 +0300</pubDate>
      
      <guid>https://bikulov.org/blog/2013/08/16/cudasafecall-application-snippet/</guid>
      <description>It is a good tone to check CUDA API errors while calling cudaMalloc() and other functions. It also helps to find floating bugs caused by hardware (lack of memory, etc). I provide below an adapted version of CudaSafeCall I found many weeks ago in the Internet. Simply remove #define CUDA_ERROR_CHECK in production if unneeded.
#include &amp;lt;iostream&amp;gt;#include &amp;lt;cuda.h&amp;gt; #define CUDA_ERROR_CHECK  #define CudaSafeCall(error) __cudaSafeCall(error, __FILE__, __LINE__)  inline void __cudaSafeCall(cudaError error, const char *file, const int line) { #ifdef CUDA_ERROR_CHECK  if (error !</description>
    </item>
    
  </channel>
</rss>
