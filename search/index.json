[{"content":"Disclaimer: many links in this post are referral. If you are uncomfortable with it, just search for the text in the links and use results from the search engines.\nPlan  Spin up a new virtual server (1 CPU + 1 GB RAM is fairly enough) in Vultr, Digital Ocean, etc. Register a new domain name Install Docker and Docker Compose Use docker-compose to deploy a wiki Backups  Virtual server For example, let it be Digital Ocean.\nYou need to create a 5$ basic droplet with Ubuntu 20.04 (Droplets -\u0026gt; Create droplet). Choose:\n Latest stable Ubuntu (in this time it is Ubuntu 20.04) Basic plan $5 size Any datacenter. Choose those that are closer to you. In additional settings check «IPv6» because it is cool 😎 Authentication: SSH is must-have, generate key if needed  Domain name One can register a domain name at the registrar of your choice. For Russian domains, I use reg.ru.\nAfter registration (and some wait time, while DNS records are being updated across the world), add resource record in DNS editor: A for IPv4 and AAAA for IPv6. IPs you can find on the virtual machine info page.\nMore about resource records: https://en.wikipedia.org/wiki/List_of_DNS_record_types\nDocker and docker-compose For installation of Docker use the official doc:\n# run as root apt install apt-transport-https ca-certificates curl gnupg-agent software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - apt-key fingerprint 0EBFCD88 add-apt-repository \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026quot; apt update \u0026amp;\u0026amp; apt install docker-ce docker-ce-cli containerd.io  And install docker-compose by the official doc:\n# run as root curl -L \u0026quot;https://github.com/docker/compose/releases/download/1.28.2/docker-compose-$(uname -s)-$(uname -m)\u0026quot; -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose  Deploy wiki You need to choose wiki to install. Let it be Dokuwiki.\nAll you need is just a single docker-compose.yaml:\nversion: \u0026quot;3.4\u0026quot; services: proxy: image: traefik:v2.0 container_name: proxy restart: always command: - \u0026quot;--providers.docker=true\u0026quot; - \u0026quot;--providers.docker.exposedbydefault=false\u0026quot; - \u0026quot;--entrypoints.web.address=:80\u0026quot; - \u0026quot;--entrypoints.websecure.address=:443\u0026quot; - \u0026quot;--certificatesresolvers.lech.acme.tlschallenge=true\u0026quot; - \u0026quot;--certificatesresolvers.lech.acme.email=blog@bikulov.org\u0026quot; - \u0026quot;--certificatesresolvers.lech.acme.storage=/letsencrypt/acme.json\u0026quot; labels: - \u0026quot;traefik.enable=true\u0026quot; - \u0026quot;traefik.http.routers.https-redirect.entrypoints=web\u0026quot; - \u0026quot;traefik.http.routers.https-redirect.rule=HostRegexp(`{any:.*}`)\u0026quot; - \u0026quot;traefik.http.routers.https-redirect.middlewares=https-redirect\u0026quot; - \u0026quot;traefik.http.middlewares.https-redirect.redirectscheme.scheme=https\u0026quot; ports: - \u0026quot;443:443\u0026quot; - \u0026quot;80:80\u0026quot; volumes: - proxy-data:/letsencrypt - /var/run/docker.sock:/var/run/docker.sock:ro dokuwiki: image: linuxserver/dokuwiki container_name: dokuwiki restart: always labels: - \u0026quot;traefik.enable=true\u0026quot; - \u0026quot;traefik.http.routers.dokuwiki.rule=Host(`wiki.bikulov.org`)\u0026quot; - \u0026quot;traefik.http.routers.dokuwiki.entrypoints=websecure\u0026quot; - \u0026quot;traefik.http.routers.dokuwiki.tls.certresolver=lech\u0026quot; environment: - PUID=1000 - PGID=1000 - TZ=Europe/Moscow volumes: - dokuwiki-data:/config volumes: proxy-data: dokuwiki-data:  You need to change:\n certificatesresolvers.lech.acme.email to your email traefik.http.routers.dokuwiki.rule to your host  There are two services proxy and dokuwiki with two data volumes. proxy knows about dokuwiki via labels. Only proxy exposes 80 and 443 ports to host machine and routes traffic to dokuwiki by matching rule Host(`wiki.bikulov.org`).\nJust run in directory with yaml:\ndocker-compose up -d  More about docker-compose. More about data volumes. More about traefic.\nBackups More at backups can be fount in the official doc. Below I rovide the most essential: backup bash command.\nBackup:\ndocker run --rm --volumes-from dokuwiki -v $(pwd):/backup ubuntu bash -c \u0026quot;tar cvfz /backup/dokuwiki_$(date +%s).tar.gz /config\u0026quot;  Restore:\n$ docker run --rm --volumes-from dokuwiki -v $(pwd):/backup ubuntu bash -c \u0026quot;cd /config \u0026amp;\u0026amp; rm -rf * \u0026amp;\u0026amp; tar xvf /backup/backup.tar --strip 1\u0026quot;  So, the last building blog is to sync tars fom server elsewhere. You can achieve it with Syncthing, Yandex Disk, rclone and many others.\n","date":"2021-02-02","permalink":"http://localhost:1313/blog/2021/02/02/how-to-setup-own-selfhosted-wiki/","tags":["howto","ubuntu","server","selfhosted","docker","dokuwiki"],"title":"How to setup own selfhosted wiki"},{"content":"WireGuard is lightweight VPN with extremely simple configuration. All below was tested on Ubuntu 18.04 as server and Anroid 8.0.0 as client.\nServer Installation from official ppa:\napt-add-repository ppa:wireguard/wireguard apt update apt install wireguard  Client and server authenticate each other with asymmetric keys (like in SSH). Keys are generated with management utility wg:\nwg genkey  This will be server auth key (client auth key can be generated with the same command or in mobile application, you will need public part in config).\nAdd configuration file sudo vim /etc/wireguard/wg0.conf:\n[Interface] Address = 10.9.0.1/24 PrivateKey = \u0026lt;generaed by wg0 private key\u0026gt; ListenPort = 51820 PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE [Peer] PublicKey = \u0026lt;public key generated on client (android app)\u0026gt; AllowedIPs = 10.9.0.2/32  And fix chmod:\nchmod 600 /etc/wireguard/wg0.conf  This configuration includes routing internet requests from VPN clients. If you do not need it (communication between server and client is enough), omit MASQUERADE lines.\nEnable systemd to autorun service:\nsudo systemctl enable wg-quick@wg0.service sudo systemctl daemon-reload  Start it manually first time:\nwg-quick up wg0  Enable web forwarding if you have kept MASQUERADE lines in the config:\nvim /etc/sysctl.conf net.ipv4.ip_forward=1  Client Install application from Play\nCreate configuration from scratch.\n Name is anything Private key can be generated with \u0026ldquo;generate\u0026rdquo; button or with wg utility on server and copied from there Addresses is the same as in client section of server (10.9.0.2/32 in this note) Listen port is any, you can keep 51820 similar to server DNS server - any, use Yandex\u0026rsquo;s 77.88.8.8 or Google\u0026rsquo;s 8.8.8.8 MTU copy from server (after starting wireguard service, run ifconfig wg0)  Peer section - server config:\n Public key: public part of server key (you can extract it fdom private with echo public key | wg pubkey) Allowed IPS: server IP 10.9.0.1 if do not want to route all traffic via server, or 0.0.0.0/0 if you want it Endpoint: server_host:server port (like myhost.com:51820) ","date":"2019-12-22","permalink":"http://localhost:1313/blog/2019/12/22/wireguard-on-ubuntu-server-and-android-client/","tags":["howto","ubuntu","VPN","server"],"title":"WireGuard on Ubuntu (server) and Android (client)"},{"content":"For every simple python script you need same simple parts:\n command line arguments parsing logging [optional] submodules [optional] building to a binary  I\u0026rsquo;ve prepared a simple python project with all these parts to use as template. It is available on github.\nCommand line arguments parsing is done in parse_arguments. The most interesting thing there is setting default fuctions for submodules (and None for main module). It looks like:\nfirst_module_parser.set_defaults(func=first_module)  and allows to address needed by chosen submodule function as simple as\nif args.func: args.func(args)  Logging initialization is simple and has only two modes: verbose (with DEBUG level enabled) and non-verbose (only INFO messages):\nlogging.basicConfig( level=logging.DEBUG if args.verbose else logging.INFO, format=\u0026quot;[%(filename)s:%(lineno)d] %(levelname)-8s [%(asctime)s] %(message)s\u0026quot;, datefmt=\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot;, )  These is also a Makefile in the project with simple compilation from python code to binary (python-\u0026gt;cython-\u0026gt;gcc-\u0026gt;binary):\ncp python_template.py python_template.pyx cython *.pyx --embed gcc -Os -I /usr/include/python3.5m -o python_template python_template.c -lpython3.5m -lpthread -lm -lutil -ldl rm python_template.pyx python_template.c  pytest test is located in the separate file test_python_template.py and may be invoced as:\nmake test  Sample output:\n$ make test py.test test_python_template.py ================================ test session starts ================================= platform linux2 -- Python 2.7.12, pytest-2.8.7, py-1.4.31, pluggy-0.3.1 rootdir: /home/bikulov/Projects/python_template, inifile: collected 3 items test_python_template.py ... ============================== 3 passed in 0.01 seconds ============================== ","date":"2019-02-22","permalink":"http://localhost:1313/blog/2019/02/22/python-program-template/","tags":["python"],"title":"Python program template"},{"content":"The most common way of sorting collections of custom objects in Python is to provide key function that is used to extract a comparison key from each element:\nsorted(\u0026quot;Case insensitive Sorting is here\u0026quot;.split(), key=str.lower)  But sorted function compares objects by its nature, and it is possible to define comparison operators for your class t make sorted work automatically.\nDocumentation guarantees that sorting uses only __lt__() method:\n The sort routines are guaranteed to use __lt__() when making comparisons between two objects. So, it is easy to add a standard sort order to a class by defining an __lt__() method.\n But it is recommended to define all comparison methods for your class for the sake of safety and code completeness. It can be done with total_ordering decorator from the functools standard module. Lets look at class:\nimport functools @functools.total_ordering class Point: def __init__(self, x, y): self.x, self.y = x, y def __lt__(self, other): return (self.x, self.y) \u0026lt; (other.x, other.y) def __eq__(self, other): return (self.x, self.y) == (other.x, other.y)  Example usage:\npoints = [Point(x, y) for x in range(2, 0, -1) for y in range(3, 0, -1)] print('Not sorted:', ', '.join(map('({0.x}, {0.y})'.format, points))) print('Sorted:', ', '.join(map('({0.x}, {0.y})'.format, sorted(points))))  will produce output:\nNot sorted: (2, 3), (2, 2), (2, 1), (1, 3), (1, 2), (1, 1) Sorted: (1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3)  total_ordering decorator is excessive here, but may be useful in the future. What it does? It completes remaining comparison methods from implemented ones. So you implement __eq__ and __lt__, it complements __le__, __gt__, __ge__. Or you implement __eq__ and __le__, it complements __lt__, __gt__, __ge__. And so on. It requires __eq__ and one other comparison method to be defined.\nEssential part of the generator code is:\ndef total_ordering(cls): \u0026quot;\u0026quot;\u0026quot;Class decorator that fills in missing ordering methods\u0026quot;\u0026quot;\u0026quot; # Find user-defined comparisons (not those inherited from object). roots = [op for op in _convert if getattr(cls, op, None) is not getattr(object, op, None)] if not roots: raise ValueError('must define at least one ordering operation: \u0026lt; \u0026gt; \u0026lt;= \u0026gt;=') root = max(roots) # prefer __lt__ to __le__ to __gt__ to __ge__ for opname, opfunc in _convert[root]: if opname not in roots: opfunc.__name__ = opname setattr(cls, opname, opfunc) return cls  where _convert is dict of predefined implementations of comparison methods via each other. Code gets all defined is cls comparison methods, prefers one (if several are defined) and defines other methods.\n","date":"2017-03-11","permalink":"http://localhost:1313/blog/2017/03/11/python-sorting-objects-of-user-defined-class/","tags":["python"],"title":"Python sorting objects of user defined class"},{"content":"LXC containers are great for application isolation and safe deployment. Running unprivileged containers is the safest way to run containers in a production environment. This note contains enough information to create your own safe container.\nInstall LXC:\napt-get install -y lxc  Now create non-root system user for lxc:\nuseradd --home-dir /srv/lxc --create-home lxc echo \u0026quot;lxc veth lxcbr0 2\u0026quot; | sudo tee -a /etc/lxc/lxc-usernet passwd lxc \u0026lt;type password\u0026gt;  I recommend to add autostart as default behaviour:\nsu lxcusr  and add lines\n# Autostart lxc.start.auto = 1 lxc.start.delay = 5  to file ~/.config/lxc/default.conf\nAdd uid mappings in ~/.config/lxc/default.conf:\n# UID mappings lxc.include = /etc/lxc/default.conf lxc.id_map = u 0 100000 65536 lxc.id_map = g 0 100000 65536  Before container creation, you must login as lxc user directly (like ssh lxc@server.name), or you will get error.\nCreate first container:\nlxc-create -t download -n sample.dima.io -- -d ubuntu -r xenial -a amd64 lxc-start -d -n sample.dima.io lxc-attach -n sample.dima.io  Don not forget to delete default user in container:\nuserdel ubuntu \u0026amp;\u0026amp; rm -rf /home/ubuntu ","date":"2016-08-19","permalink":"http://localhost:1313/blog/2016/08/19/tips-for-lxc-2-unprivileged-containers/","tags":["lxc","server","howto","ubuntu"],"title":"Tips for LXC 2: unprivileged containers"},{"content":"Ubuntu has a very detailed documentation about OpenVPN server configuration. The key feature of this note is script for automatic generation of single-file client configurations (keys and certs are embedded) and sending them by email. Looks interesting? Read below!\nPrerequisities All commands in this section must be executed as root user.\nUpdate package list:\napt-get update apt-get -y upgrade  Install needed packages (easy-rsa must be installed explicitly on modern Ubuntus):\napt-get install -y openvpn easy-rsa  Configure OpenVPN server on Ubuntu 14.04 Copy default configuration:\ncp -r /usr/share/easy-rsa /etc/openvpn/easy-rsa cd /etc/openvpn/easy-rsa  Edit vars file in /etc/openvpn/easy-rsa folder corresponding to your settings. Change the following lines corresponding to your options:\nexport KEY_SIZE=2048 export KEY_COUNTRY=\u0026quot;US\u0026quot; export KEY_PROVINCE=\u0026quot;State\u0026quot; export KEY_CITY=\u0026quot;BigCityName\u0026quot; export KEY_ORG=\u0026quot;OrganizationName\u0026quot; export KEY_EMAIL=\u0026quot;mail@organization.com\u0026quot; export KEY_OU=\u0026quot;vpn.organization.com\u0026quot; export KEY_NAME=\u0026quot;vpn.organization.com\u0026quot; export KEY_CN=\u0026quot;vpn.organization.com\u0026quot; export KEY_ALTNAMES=\u0026quot;vpn.organization.com\u0026quot;  Activate saved settings:\nsource vars  And generate server keys:\n./clean-all ./build-ca ./build-key-server vpn.organization.com ./build-dh openvpn --genkey --secret keys/ta.key  Example of server config (must be placed into /etc/openvpn folder):\n# /etc/openvpn/server.conf # Which TCP/UDP port should OpenVPN listen on port 1594 # Ip's server 10.10.10.0 255.255.255.0 # UDP server proto udp # Create a routed IP tunnel dev tun # Root certificate, certificate, private key, DH key, SSL/TLS key ca easy-rsa/keys/ca.crt cert easy-rsa/keys/vpn.organization.com.crt key easy-rsa/keys/vpn.organization.com.key dh easy-rsa/keys/dh2048.pem tls-auth easy-rsa/keys/ta.key 0 # Maintain a record of client \u0026lt;-\u0026gt; virtual IP address ifconfig-pool-persist ipp.txt # Allow different clients to be able to \u0026quot;see\u0026quot; each other client-to-client # Ping every 10 seconds, peer is down if no pong during a 120 seconds keepalive 10 120 # Cryptographic cipher cipher AES-256-CBC # Enable compression on the VPN link comp-lzo # Reduce the OpenVPN daemon's privileges after initialization user nobody group nogroup # Avoid errors caused by the privilege downgrade persist-key persist-tun # Status file status openvpn-status.log # Set the appropriate level of log verbosity verb 3  Be sure that your keys ca.crt, vpn.organization.com.crt, vpn.organization.com.key, dh2048.pem, ta.key are in the correct place corresponding to server config.\nClient configuration Client configuration must correspond to server one. For the above server config client one is:\n# /etc/openvpn/easy-rsa/client.conf # Specify that it is a client client # Use the same setting as on the server. dev tun proto udp # The hostname/IP and port of the server. remote vpn.organization.com 1594 # Keep trying indefinitely to resolve the host name of the OpenVPN server resolv-retry infinite # Most clients don't need to bind to a specific local port number nobind # Downgrade privileges after initialization (non-Windows only) user nobody group nogroup # Try to preserve some state across restarts persist-key persist-tun # Verify server certificate ns-cert-type server # Enable compression on the VPN link comp-lzo # Set log file verbosity. verb 3 # Set key direction for tls-auth key-direction 1 # Cryptographic cipher cipher AES-256-CBC  Сonvenient autosending of client configurations Save the following script into folder:\n#!/usr/bin/env bash CLIENT=$1 CLIENT_MAIL=$2 SERVER=vpn.dima.io cd /etc/openvpn/easy-rsa source vars mkdir -p bundles ./build-key ${CLIENT}.at.${SERVER} cp client.conf bundles/${CLIENT}.at.${SERVER}.conf echo \u0026quot;\u0026lt;ca\u0026gt;\u0026quot; \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf cat keys/ca.crt \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf echo \u0026quot;\u0026lt;/ca\u0026gt;\u0026quot; \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf echo \u0026quot;\u0026lt;cert\u0026gt;\u0026quot; \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf cat keys/${CLIENT}.at.${SERVER}.crt \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf echo \u0026quot;\u0026lt;/cert\u0026gt;\u0026quot; \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf echo \u0026quot;\u0026lt;key\u0026gt;\u0026quot; \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf cat keys/${CLIENT}.at.${SERVER}.key \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf echo \u0026quot;\u0026lt;/key\u0026gt;\u0026quot; \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf echo \u0026quot;\u0026lt;tls-auth\u0026gt;\u0026quot; \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf cat keys/ta.key \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf echo \u0026quot;\u0026lt;/tls-auth\u0026gt;\u0026quot; \u0026gt;\u0026gt; bundles/${CLIENT}.at.${SERVER}.conf if [ -n \u0026quot;$CLIENT_MAIL\u0026quot; ]; then echo -e \u0026quot;Hello, ${CLIENT}!\\n\\nConfiguration with embedded certificates is attached.\u0026quot; \u0026gt; mail.txt echo \u0026quot;If you use Windows system, rename configuration from *.conf to *.ovpn.\u0026quot; \u0026gt;\u0026gt; mail.txt echo \u0026quot;This mail is automatically generated. Please do not respond to it.\u0026quot; \u0026gt;\u0026gt; mail.txt echo \u0026quot;--\u0026quot; echo \u0026quot;${SERVER} team.\u0026quot; cat mail.txt | mutt -s \u0026quot;Configuration for $CLIENT on $SERVER OpenVPN server\u0026quot; -a bundles/${CLIENT}.at.${SERVER}.conf -- $CLIENT_MAIL fi rm mail.txt  add-key\nAnd make it executable:\nchmod +x add-key  You will have to install mutt (it is used for sending emails with attachments). Your server must have full hostname like server.organization.com, otherwise sendmail may hang during the install, so change it before mutt installation.\napt-get install -y mutt  If you install in LXC container If you install VPN server into LXC container, you have to make additional steps. Firstly, add rule for iptabels in host system (use ip of your VPN container and port from VPN server config):\niptables -t nat -A PREROUTING -i eth0 -p udp --dport 1594 -j DNAT --to 10.0.3.111:1594  To make it persistent, you may use iptables-persistent.\nSecondly, confugure tun device for lxc.\n","date":"2016-01-05","permalink":"http://localhost:1313/blog/2016/01/05/script-for-user-configurations-generation-and-sending-at-ubuntu-openvpn-server/","tags":["openvpn","ubuntu","howto","script"],"title":"Script for user configurations generation and sending at Ubuntu OpenVPN server"},{"content":"Several changes occured since my last note about installing python scientific environment:\n IPython Notebook was succeeded by Jupyter Notebook seaborn package is used for the pretty matplotlib plots raw virtualenv was replaced by virtualenvwrapper procedure of notebook profiles creation and edition has been changed ipython bug about pip in virtualenv is obsolete. But now another workaround is needed for packahes installation pip installation from pypa is now one-liner  Install prerequisities as root:\n# install curl virtualenvwrapper apt-get install -y curl virtualenvwrapper # install as workaround for https://github.com/matplotlib/matplotlib/issues/3029/ apt-get install -y pkg-config # install python development packages and g++ apt-get install -y python3-dev g++ # install dependencies for scipy apt-get install -y libblas-dev liblapack-dev gfortran # install some dependencies for matplotlib apt-get install -y libfreetype6-dev libpng-dev libjpeg8-dev  Now create and activate virtualenv, install all the packages via pip:\n# create and activate virtual environment using mkvirtualenv wrapper (env name is jupnb) mkvirtualenv --no-setuptools --python /usr/bin/python3.4 jupnb # install fresh pip curl https://bootstrap.pypa.io/get-pip.py | python # install fresh setuptools pip install setuptools distribute # install numpy as it is dependecy for many others pip install numpy # install scientific packages (seaborn instead of matplotlib for pretty plots) pip install sympy scipy seaborn pandas jupyter # install scikit-learn separately, it depends on numpy and scipy pip install scikit-learn # deactivate venv deactivate  Configure notebook profile with SSL encryption. Use real ssl certificate instead of self-generated (if you have one). You can use jupyter notebook --generate-config command to create default config with comments about all the options, or use following snippet for minimal config generation:\nmkdir -p ~/.jupyter cd ~/.jupyter openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout ${ENV}.pem -out jupnb.pem echo \u0026quot;c.NotebookApp.ip = '*'\u0026quot; \u0026gt;\u0026gt; jupyter_notebook_config.py echo \u0026quot;c.NotebookApp.port = 8888\u0026quot; \u0026gt;\u0026gt; jupyter_notebook_config.py echo \u0026quot;c.NotebookApp.open_browser = False\u0026quot; \u0026gt;\u0026gt; jupyter_notebook_config.py echo \u0026quot;c.NotebookApp.password = u'$(ipython -c 'from notebook.auth import passwd; print(passwd())')'\u0026quot; \u0026gt;\u0026gt; jupyter_notebook_config.py echo \u0026quot;c.NotebookApp.certfile = u'jupnb.pem'\u0026quot; \u0026gt;\u0026gt; jupyter_notebook_config.py echo \u0026quot;c.NotebookApp.cookie_secret_file = '$HOME/.jupyter/secret_cookie'\u0026quot; \u0026gt;\u0026gt; jupyter_notebook_config.py cd -  That\u0026rsquo;s all. To use notebook, activate virtual env, run server and open http://127.0.0.1:8888/ in your browser:\nworkon jupnb jupyter notebook ","date":"2015-11-07","permalink":"http://localhost:1313/blog/2015/11/07/install-jupyter-notebook-and-scientific-environment-in-ubuntu-14.04-with-python-3/","tags":["ubuntu","howto","python","jupyter","ipython","numpy","scipy","seaborn"],"title":"Install Jupyter Notebook and Scientific Environment in Ubuntu 14.04 With Python 3"},{"content":"Console utilities in Linuxes are cool: mcabber for jabber, mutt for mail, mocp for music, vim to rule them all! This note is about scaning from the console (I assume your scanner is already set-up). Aim is to scan document with good quality into pdf with reasonable size.\nScanning is done by scanimage utility:\nscanimage --resolution 300 --mode Color --format tiff \u0026gt; document.tiff  If there is more than one scanner in your system, list them all by scanimage -L commant and use specify name with --device-name argument.\nNext step is to convert tiff into pdf image. It can be done with imagemagick:\nconvert document.tiff document-big.pdf  But resulting pdf is too big and must be reduced. I\u0026rsquo;ve found shrinkpdf bash script very helpful for this purpose with correction: IMHO 72 DPI resolution is too small, so I\u0026rsquo;ve changed it to 300 dpi. Essential part of that script is ghostscript call:\ngs -q -dNOPAUSE -dBATCH -dSAFER \\ -sDEVICE=pdfwrite \\ -dCompatibilityLevel=1.3 \\ -dPDFSETTINGS=/screen \\ -dEmbedAllFonts=true \\ -dSubsetFonts=true \\ -dColorImageDownsampleType=/Bicubic \\ -dColorImageResolution=300 \\ -dGrayImageDownsampleType=/Bicubic \\ -dGrayImageResolution=300 \\ -dMonoImageDownsampleType=/Bicubic \\ -dMonoImageResolution=300 \\ -sOutputFile=document.pdf \\ document-big.pdf ","date":"2015-09-26","permalink":"http://localhost:1313/blog/2015/09/26/scan-images-from-command-line-in-linux/","tags":["linux","scanimage","scan","pdf","tiff","howto"],"title":"Scan images from command line in Linux"},{"content":"Create frames This note describes usage of Paraview 4.3 (contrary to previous note with Paraview before 4.1). Some changes were made:\n command line arguments were added to make code more reusable it works with Paraview extracted from the archive (4.3.1) white background must be specified manually (SetViewProperties(view, Background = [1, 1, 1]) in the code)  Script is tested under Ubuntu 14.04 with Paraview 4.3.1. Paraview was downloaded from official site and extracted to /home/bikulov/bin/ParaView-4.3.1-Linux-64bit/lib/paraview-4.3 (you have to change this line in script to your destination). State file must be prepared in the same Paraview 4.3.1 to avoid compatibility issues (or you may have errors about ColorArrayName).\nScript (also available as a gist):\n#!/usr/bin/env python import os, sys import glob, natsort, argparse ParaviewPath=\u0026quot;/home/bikulov/bin/ParaView-4.3.1-Linux-64bit/lib/paraview-4.3\u0026quot; print(\u0026quot;export LD_LIBRARY_PATH={ParaviewPath}:$LD_LIBRARY_PATH\u0026quot;.format(ParaviewPath=ParaviewPath)) sys.path.append(os.path.join(ParaviewPath, \u0026quot;site-packages\u0026quot;)) sys.path.append(os.path.join(ParaviewPath, \u0026quot;site-packages/vtk\u0026quot;)) from paraview.simple import * def main(pipeline, state, files, output): filenames = natsort.natsorted(files) servermanager.LoadState(state) view = servermanager.GetRenderView() camera = view.GetActiveCamera() phase = FindSource(pipeline) # Set white background SetViewProperties(view, Background = [1, 1, 1]) try: os.makedirs(output) except: pass imgNum = 0 for f in filenames: phase.FilePrefix = f phase.FileNameChanged() view.WriteImage(os.path.join(output, str(imgNum).zfill(6) + \u0026quot;.png\u0026quot;), \u0026quot;vtkPNGWriter\u0026quot;, 1) imgNum += 1 if __name__ == \u0026quot;__main__\u0026quot;: parser = argparse.ArgumentParser(prog=\u0026quot;PROG\u0026quot;, description=\u0026quot;Draw With Paraview\u0026quot;) parser.add_argument(\u0026quot;--state\u0026quot;, type=str, help=\u0026quot;State file to load\u0026quot;, default=\u0026quot;state.pvsm\u0026quot;) parser.add_argument(\u0026quot;--pipeline\u0026quot;, type=str, help=\u0026quot;Pipiline name for changing file\u0026quot;, default=\u0026quot;data\u0026quot;) parser.add_argument(\u0026quot;--output\u0026quot;, type=str, help=\u0026quot;Output path for images\u0026quot;, default=\u0026quot;img\u0026quot;) parser.add_argument(\u0026quot;files\u0026quot;, nargs=\u0026quot;*\u0026quot;, help=\u0026quot;Files to be used in the pipeline\u0026quot;) args = parser.parse_args() main(pipeline=args.pipeline, state=args.state, files=args.files, output=args.output)  Command line arguments explanation:\n --state is filename with state to be loaded (File-\u0026gt;Save State in Paraview) --pipeline is the name of pipeline inside state (item in Pipeline browser, for which you want to change File Prefix) --output is path to dir where images will be saved files are bunch of raw binary images you whant to visualize as video  Example run (will process all *-phase.raw files in directory and save resulting images into imgtest directory):\n./draw_with_paraview.py --state state.pvsm --pipeline data --output imgtest *-phase.raw  Note: you must add path to paraview libraries in LD_LIBRARY_PATH before run (script prints out this line for convenience):\nexport LD_LIBRARY_PATH=/home/bikulov/bin/ParaView-4.3.1-Linux-64bit/lib/paraview-4.3:$LD_LIBRARY_PATH  Postprocess frames You may want to crop images in the output folder. For mp4 width and height must be divisible by two, so you may need to crop for identify them accordingly (in parallel for speed):\nimg=$(ls *.png|head -n 1) width=$(($(identify -format \u0026quot;(%[fx:w]/2)*2\u0026quot; ${img}))) height=$(($(identify -format \u0026quot;(%[fx:h]/2)*2\u0026quot; ${img}))) find -name '*.png' -exec mogrify -crop \u0026quot;${width}x${height}+0+0\u0026quot; {} +  Or the same commands in one line:\nimg=$(ls *.png|head -n 1); width=$(($(identify -format \u0026quot;(%[fx:w]/2)*2\u0026quot; ${img}))); height=$(($(identify -format \u0026quot;(%[fx:h]/2)*2\u0026quot; ${img}))); find -name '*.png' -exec mogrify -crop \u0026quot;${width}x${height}+0+0\u0026quot; {} +  You may also need to crop images to some specific size, just use the final line:\nfind -name '*.png' -exec mogrify -crop \u0026lt;width\u0026gt;x\u0026lt;height\u0026gt;+\u0026lt;x_shift\u0026gt;+\u0026lt;y_shift\u0026gt; {} +  Create animation from the frames Create video from images (ffmpeg no longer supported, so use avconv):\navconf -qscale 1 -r 20 -b 9600 -i %06d.png output_file.mp4 ","date":"2015-04-05","permalink":"http://localhost:1313/blog/2015/04/05/animations-from-scientific-data-using-paraview-4.3-and-python/","tags":["paraview","python","ubuntu","howto"],"title":"Animations from scientific data using Paraview 4.3 and python"},{"content":"Lately NVIDIA added repository for Ubuntu 12.04 and Ubuntu 14.04. Recently I hit problem with missing dependencies for libcheese-gtk23 and libcheese7 libraries while installing latest CUDA 6.5 on clean Ubuntu 14.04. Remedy to this can be found on askubuntu. So, the complete set of commands is below.\nAt first, add CUDA repository package:\nwget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_6.5-14_amd64.deb sudo dpkg -i cuda-repo-ubuntu1404_6.5-14_amd64.deb  Now, install CUDA:\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get upgrade # install nvidia driver sudo apt-get install nvidia-current # at this point you need to reboot computer # remove broken packages, beware: some GUI parts of your system will be broken or removed sudo apt-get remove libcheese* # install CUDA sudo apt-get install cuda # restore broken GUI parts sudo apt-get install ubuntu-desktop  By the way, libcheese is library for video and photo capturing, including enumeration of capturing devices.\n","date":"2015-02-28","permalink":"http://localhost:1313/blog/2015/02/28/install-cuda-6.5-on-clean-ubuntu-14.04/","tags":["ubuntu","cuda","howto","libcheese"],"title":"Install CUDA 6.5 on clean Ubuntu 14.04"},{"content":"See updated note.\nOne of the common tasks in computer modeling is visualization of numerical experiment as a movie. Usually it is one datafile per frame and target is to create frame-by-frame animation. If these files can be loaded and visualized in Paraview, it is easy to create the full video: load file in paraview with predefined parameters, create screenshot, load second file, etc. This process may be automated.\nWe will use latest stable build of Paraview from official site. Note: latest version of Paraview has strange error: it loses color while rendering. You may use previous Paraview 4.1 without this bug.\nExtract tarball into ~/bin/paraview folder. Run paraview and prepare scene as you like. Remember the name of the pipeline with file you want to change every frame (in my case it is data). Save state (File-\u0026gt;Save State) in folder with datafiles you want to visualize as state.pvsm.\nParaview with prepared state: Now we need for every file:\n change pipeline data file for frame render it save frame picture  It can be done with following python 2 script:\n#!/usr/bin/env python from sys import path path.append(\u0026quot;/home/bikulov/bin/paraview/lib/paraview-4.2/site-packages\u0026quot;) path.append(\u0026quot;/home/bikulov/bin/paraview/lib/paraview-4.2/site-packages/vtk\u0026quot;) path.append(\u0026quot;/home/bikulov/bin/paraview/lib/paraview-4.2\u0026quot;) import glob, natsort, os from paraview.simple import * filenames = natsort.natsorted(glob.glob(\u0026quot;*.raw\u0026quot;)) servermanager.LoadState(\u0026quot;state.pvsm\u0026quot;) view = servermanager.GetRenderView() camera = view.GetActiveCamera() phase = FindSource('data') try: os.makedirs(\u0026quot;img\u0026quot;) except: pass imgNum = 0 phase.FilePrefix = filenames[0] phase.FileNameChanged() view.WriteImage(\u0026quot;img/\u0026quot;+str(imgNum).zfill(6)+\u0026quot;.png\u0026quot;,\u0026quot;vtkPNGWriter\u0026quot;,1) for file in filenames: phase.FilePrefix = file phase.FileNameChanged() view.WriteImage(\u0026quot;img/\u0026quot;+str(imgNum).zfill(6)+\u0026quot;.png\u0026quot;,\u0026quot;vtkPNGWriter\u0026quot;,1) imgNum += 1  All images will be created in img folder, crop them and build video with mogrify and ffmpeg (you may need to replace ffmpeg with avconv in newer versions of Ubuntu).\n","date":"2014-11-15","permalink":"http://localhost:1313/blog/2014/11/15/create-video-illustrations-from-numerical-experiments-data-with-paraview-and-python-2/","tags":["paraview","python","science","visualization"],"title":"Create video illustrations from numerical experiments data with Paraview and Python 2"},{"content":"I\u0026rsquo;ve completed setting up my comfort set of LXC containers and want to save some points I spent a lot of time for or things for copy-paste.\nI used the official Ubuntu Server Guide but note at Digital Ocean knowledge base also helped me a lot. I created 3 containers: one for vpn, one for site on Drupal and last one as www proxy for second one with nginx only.\nCreate LXC container Pretty simple, create container with Ubuntu in it:\nlxc-create -n [container_name] -t ubuntu  Next, start it:\nlxc-start -d -n [container_name]  where -d arg is essential, otherwise you will fell into containers command line and stuck in it.\nAttach to started container:\nlxc-attach -n [container_name]  All containers are created with default user:password «ubuntu:ubuntu». I strongly recommend to delete it, it is out of use:\nuserdel ubuntu rm -rf /home/ubuntu  Autostart LXC container I wanted all my containers to start automatically. You can find instructions in Ubuntu server guide (edit /var/lib/lxc/[container_name]/config):\n# Autostart lxc.start.auto = 1 lxc.start.delay = 5  Read as follows: autostart container and wait 5 seconds before starting next one.\nOpenVPN in LXC VPN server is not working out-of-box in LXC container. You need to add following option in container config (/var/lib/lxc/[container_name]/config):\n# OpenVPN lxc.cgroup.devices.allow = c 10:200 rwm  At first time you will also need to run commands as root to create file for tun device:\nmkdir /dev/net mknod /dev/net/tun c 10 200 chmod 0666 /dev/net/tun  Notes from heider.io and boxtricks helped me.\nIptables with LXC containers I needed to forward 80 and 443 ports to container with ip 10.0.3.100 and 1194 (OpenVPN) port to 10.0.3.200. To do so, perform at host machine:\niptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j DNAT --to 10.0.3.100:80 iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 443 -j DNAT --to 10.0.3.100:443 iptables -t nat -A PREROUTING -i eth0 -p udp --dport 1194 -j DNAT --to 10.0.3.200:1194  but these changes will be lost after reboot. To save them, install iptables-persistent:\napt-get install -y iptables-persistent  and agree to save current iptables settings.\nThe last problem was that iptables rules are correct, but not loaded by iptables-persistent. But if I run service iptables-persistent start manually after booting, everything is ok, port forwarding works. In /var/lib/boot.log I saw line:\nLoading iptables rules... [fail]  I believe, the problem is in boot and init order, so I added iptables-persistent start after network is up. Create file /etc/network/if-up.d/iptables-persistent:\n#!/usr/bin/env bash service iptables-persistent start  and make it executable:\nchmod +x /etc/network/if-up.d/iptables-persistent  At next boot iptables will fall at boot, but will be reloaded after network is up.\n","date":"2014-10-09","permalink":"http://localhost:1313/blog/2014/10/09/tips-for-lxc-creation-autostart-openvpn-and-port-forwarding-to-containers/","tags":["ubuntu","howto","server","lxc","openvpn","iptables"],"title":"Tips for LXC: creation, autostart, OpenVPN and port forwarding to containers"},{"content":"This note is similar to previous drupal and joomla installations. Install requirements (webserver, php5, DB server, DB adapter for php) as root:\napt-get install -y nginx php5-fpm nginx postgresql php5-pgsql php5-gd  Create user and database (replace USER with desired username and HOSTNAME_db with database name, we will need this values in Drupal setup later) for future site:\nsudo -u postgres -i createuser USER --pwprompt --encrypted createdb HOSTNAME_db exit  Now setup nginx. First create fastcgi config /etc/nginx/fastcgi.conf:\n# vim /etc/nginx/fastcgi.conf fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param REQUEST_URI $request_uri; fastcgi_param DOCUMENT_URI $document_uri; fastcgi_param DOCUMENT_ROOT $document_root; fastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param GATEWAY_INTERFACE CGI/1.1; fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; fastcgi_param REMOTE_ADDR $remote_addr; fastcgi_param REMOTE_PORT $remote_port; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; fastcgi_param HTTPS $https; fastcgi_param REDIRECT_STATUS 200;  Now create config for site (change HOSTNAME to your site hostname):\n#vim /etc/nginx/sites-available/HOSTNAME server { listen 80; server_name HOSTNAME; access_log /var/log/nginx/HOSTNAME.access.log; error_log /var/log/nginx/HOSTNAME.error.log; root /srv/HOSTNAME; index index.php index.html index.htm default.html default.htm; # Support Clean (aka Search Engine Friendly) URLs location / { try_files $uri $uri/ /index.php?$args; } # deny running scripts inside writable directories location ~* /(images|cache|media|logs|tmp)/.*\\.(php|pl|py|jsp|asp|sh|cgi)$ { return 403; error_page 403 /403_error.html; } location ~ \\.php$ { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include /etc/nginx/fastcgi.conf; } # caching of files location ~* \\.(ico|pdf|flv)$ { expires 1y; } location ~* \\.(js|css|png|jpg|jpeg|gif|swf|xml|txt)$ { expires 14d; } }  and enable it:\nln -s /etc/nginx/sites-available/HOSTNAME /etc/nginx/sites-enabled/  Now you need to restart services as root:\nservice php5-fpm restart service nginx restart  Download latest Drupal package to /srv/ and unpack it. Rename folder to HOSTNAME (see nginx config for host). Create settings from sample ones and change owner of /srv/HOSTNAME to www-data:www-data. Remove unnecessary Drupal package archive. All command above must look like (as root):\nwget http://ftp.drupal.org/files/projects/drupal-7.31.tar.gz tar xvf drupal-7.31.tar.gz mv drupal-7.31 bikulov.org rm drupal-7.31.tar.gz cp bikulov.org/sites/default/default.settings.php bikulov.org/sites/default/settings.php chown -R www-data:www-data bikulov.org  Now complete web install of Drupal using your database name and user.\n","date":"2014-08-09","permalink":"http://localhost:1313/blog/2014/08/09/setup-drupal-7-with-nginx-and-postgresql-on-ubuntu-14.04/","tags":["ubuntu","howto","server","nginx","postgresql"],"title":"Setup Drupal 7 with nginx and PostgreSQL on Ubuntu 14.04"},{"content":"Note: I\u0026rsquo;ve created an updated page with most recent instructions for Jupyter Notebook.\nI use IPython notebook for processing numerical experiments results and plotting. The default Python 3 in Ubuntu 14.04 is 3.4, so it is easier to install really up-to-date bunch of software.\nFull set of commands you need to install recent ipython notebook, numpy, scipy, etc in virtual environment almost without affecting shiny-new Ubuntu 14.04.\n#!/usr/bin/env bash sudo su # install python development packages and g++ apt-get install -y python3-dev g++ # install dependencies for scipy apt-get install -y libblas-dev liblapack-dev gfortran # install dependencies for matplotlib apt-get install -y libfreetype6-dev libpng-dev exit # ipython notebook has bug: # https://bugs.launchpad.net/ubuntu/+source/python3.4/+bug/1290847 python3 -m venv --clear --without-pip venv/ipython-notebook # activate virtual env and install pip source venv/ipython-notebook/bin/activate wget https://bootstrap.pypa.io/get-pip.py python get-pip.py rm get-pip.py # install scientific packages pip install numpy sympy matplotlib scipy pandas # install ipython notebook and dependencies pip install ipython pyzmq jinja2 pygments bokeh # install latest dev scikit-learn and build it pip install cython https://github.com/scikit-learn/scikit-learn/archive/master.zip # install prettyplotlib by Olga Botvinnik for beauty plots pip install brewer2mpl prettyplotlib # deactivate venv deactivate  Now create profile for ipython notebook and change there some settings. Activate virtual environment:\nbikulov@kbux:~$ source venv/ipython-notebook/bin/activate  Generate password and exit ipython:\nipython from IPython.lib import passwd; passwd() exit()  Copy password hash to clipboard. Create profile with desired name:\nipython profile create [name]  Open ~/.ipython/profile_[name]/ipython_notebook_config.py and change settings:\nc.NotebookApp.port = 8888 c.NotebookApp.ip = '0.0.0.0' c.NotebookApp.open_browser = False c.NotebookApp.password = [password hash]  Start ipython notebook server:\nipython notebook --profile=[name]  And open http://127.0.0.1:8888/ in your browser.\n","date":"2014-05-14","permalink":"http://localhost:1313/blog/2014/05/14/install-up-to-date-scientific-environment-in-ubuntu-14.04-with-python-3.4/","tags":["ubuntu","howto","python"],"title":"Install up-to-date scientific environment in Ubuntu 14.04 with Python 3.4"},{"content":"Zotero is an open source plugin for Firefox for managing research papers collections. You can use online zotero storage (pretty small) or use third-party sync application. I use Yandex Disk for this purpose: 10 Gb it quite enough for a moderate research library. zotero can automatically fetch article metadata (author, year, etc) from the web (like Mendeley and similar software do).\nPrerequisities You will need:\n Firefox (the latest version for Ubuntu 12.04 can be installed via official ppa) Zotero plugin for firefox Zotfile addon for Zotero Yandex disk or Dropbox for syncing settings and library between devices Optionally on android device: ** FolderSync Lite for syncing library folder automatically ** RepliGo pdf Reader or another pdf reader. RepliGo pdf Reader is paid, but it can add annotations and pretty smooth.  Zotfile is feature-rich addon for Zotero, but I use it for two purposes only:\n Rename and Move Attachments based on Zotero Metadata Extract Annotations from pdf files  After installation of Zotero and Zotfile you will need to restart Firefox.\nI’ve created Zotero folder in my Yandex.Disk with two subfolders: Data for Zotero database and misc files and Library for renamed pdfs. No additional internal structure in Library is used: I wanted plain list of articles and books with name template Author2010.pdf.\nConfiguring Zotero Here I’d like to list several important options to change. You can toggle zotero pane visibility with shortkey (Ctrl+Shift+Z by default).\n Settings\u0026gt; Preferences\u0026gt; Advanced\u0026gt; General: Switch Status bar icon to None (now you can hide plugin panel at the bottom of Firefox window). Settings\u0026gt; Preferences\u0026gt; Search: Install plugins for pdf indexing (it also need to extract metadata from pdf). Settings\u0026gt; Preferences\u0026gt; Advanced\u0026gt; Files and Folders: Set Base directory to ~/Yandex.Disk/Zotero, and Zotero database Data Directory Location to ~/Yandex.Disk/Zotero/Data.  Now you will be asked to quit Firefox. Do it and move old Data directory to a new location: move all data from ~/.mozilla/firefox/\u0026lt;random_string\u0026gt;/zotero/ to ~/Yandex.Disk/Zotero/Data.\nNow start zotero again.\nConfiguring Zotfile Zotfile has many options for renaming files based on article attributes: year, author, etc. I use Author2010.pdf format, i.e. first author family name and full year.\n Settings\u0026gt; Zotfile Preferences set Location Of Files to ~/Yandex.Disk/Zotero/Library. Renamed article files will be moved there.  Set up Author2010 format for renaming. In Settings\u0026gt; Zotfile Preferences\u0026gt; Renaming Rules set Format for all Item Types except Patents to {\\%a}{\\%y}. I’ve also set Maximum number of authors to 1 and removed check at Add suffix when authors are omitted.\nSome books are in djvu format, allow djvu handling: at Settings\u0026gt; Zotfile Preferences\u0026gt; Advanced Settings\u0026gt; Other Advanced Settings add djvu to Only work with the following filetypes.\nWorkflow Now, instead of downloading pdf file I can Save to Zotero and Retrieve metadata from pdf automatically. Then I open Zotero pane (Ctrl+Shift+Z by default), right click on newly added item in libary and choose Manage Attachments\u0026gt; Rename Attachments. This will rename file according to defined in zotfile preferences format and move it to the Library subfolder. Double click on item will open file in Firefox’s embedded pdf viewer.\nIn almost all cases metadata is extracted and downloaded correctly.\nAndroid side Syncing with mobile device is strongly needed. Otherwise, I need two-way sync for downloading annotated pdfs from tablet back to desktop computer. For this purpose I use free app FolderSync Lite. This app can download and upload the whole folder from many cloud-based storage providers, Yandex.Disk among them. So, I set up two-way sync of Library subfolder.\nFor reading and annotating I recommend RepliGo PDF Reader. It is paid application.\nScreenshot: ","date":"2014-02-13","permalink":"http://localhost:1313/blog/2014/02/13/research-papers-management-with-zotero-and-yandex.disk/","tags":["firefox","research","yandex.disk","zotero","zotfile"],"title":"Research Papers Management With Zotero and Yandex.Disk"},{"content":"Often some hosts in corporate network are available only from several gateway machines. The scheme looks like that: you connect to gateway ssh -A gateway.public.net and then to desired host from gateway machines ssh -A host.private.net. But the problem arises when you want to copy or download something from host.private.net. You have to do it in two hops, because host.private.net is not available from your machine directly. The solution is ssh forwarding.\nJust add the following (edit according your network settings) lines to ~/.ssh/config:\nHost gateway User bikulov ForwardAgent yes HostName gateway.public.net IdentityFile ~/.ssh/bikulov_private_key Host host User bikulov ForwardAgent yes ProxyCommand ssh -4 gateway nc -q 0 host.private.net 22  ForwardAgent options forwards information about your ssh key bikulov_private_key to gateway.public.net. Now you can just type ssh host in terminal. You will be connected to host.private.net through gateway.public.net automatically. And scp now works directly too.\n","date":"2014-01-25","permalink":"http://localhost:1313/blog/2014/01/25/ssh-config-for-multiple-hops-in-linux/","tags":["linux","howto","ssh","config"],"title":"SSH config for multiple hops in Linux"},{"content":"Makefiles are quite straightforward and easy to write (in reasonable situations). But GNU Make is not crossplafrom. CMake is cross-platform, cross-application (it can generate projects for different IDEs and Makefile itself).\nIt also allows you to split source directory and directory with intermediate files and compiled binary. Now CMake natively supports CUDA.\nHere is CMakeLists.txt example I use (simply place it next to your source files to try yourself):\nCMAKE_MINIMUM_REQUIRED(VERSION 2.8) PROJECT(lbmslv) FIND_PACKAGE(CUDA REQUIRED) FIND_PACKAGE(MPI REQUIRED) INCLUDE(FindCUDA) INCLUDE_DIRECTORIES(/usr/local/cuda/include ${MPI_INCLUDE_PATH}) FILE(GLOB SOURCES \u0026quot;*.cu\u0026quot; \u0026quot;*.cpp\u0026quot; \u0026quot;*.c\u0026quot; \u0026quot;*.h\u0026quot;) CUDA_ADD_EXECUTABLE(lbmslv ${SOURCES}) LIST(APPEND CMAKE_CXX_FLAGS \u0026quot;-std=c++0x -O3 -ffast-math -Wall\u0026quot;) LIST(APPEND CUDA_NVCC_FLAGS --compiler-options -fno-strict-aliasing -lineinfo -use_fast_math -Xptxas -dlcm=cg) LIST(APPEND CUDA_NVCC_FLAGS -gencode arch=compute_20,code=sm_20) LIST(APPEND CUDA_NVCC_FLAGS -gencode arch=compute_30,code=sm_30) LIST(APPEND CUDA_NVCC_FLAGS -gencode arch=compute_35,code=sm_35) TARGET_LINK_LIBRARIES(lbmslv /usr/local/cuda/lib64/libcudart.so ${MPI_LIBRARIES})  This file automatically adds all sources in the same directory it is placed. I\u0026rsquo;ve also included lines for newer GPU architectures (feel free to uncomment them). I prefer to choose one to reduce compilation time. It aso switches on new (phah, new for 3 years :)) C++ standart.\nSo, create CMakeLists.txt file and place it in your sources directory (say src). Then create bin (choose another name if you want) directory next to src. Change directory to bin, generate Makefile from CMakeLists.txt and build it with ordinary make:\ncd bin cmake ../src make  I\u0026rsquo;ve updated MPI part. Now it is correct.\n","date":"2013-12-24","permalink":"http://localhost:1313/blog/2013/12/24/example-of-cmake-file-for-cuda-cpp-code/","tags":["CUDA","C++","cmake"],"title":"Example of CMake file for CUDA+CPP code"},{"content":"There is base class exception in standard library (header \u0026lt;exception\u0026gt;). It has default constructor, copy constructor, copy operator and destructor and virtual what() function. Latter returns string with additional information about exception.\n#include \u0026lt;exception\u0026gt; class MyException: public std::exception { virtual const char* what() const throw() { return \u0026quot;My Exception happened\u0026quot;; } }  The most confusing part in the above code is throw(). It assures no exception will be thrown from the what() function. For example, if you want to allow exception int and float to be raised in this function, you must write throw(int,float) (you can not do it in the above example, this fucntion definition is fixed in base class). Ok, this example is mostly unchangable, so let\u0026rsquo;s write own MyException class without derivation from any standard library class.\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; class MyException { public: std::string what() { return \u0026quot;MyException happened\u0026quot;; } }; int main(int argc, char **argv) { MyException a; try { throw a; } catch (MyException \u0026amp;e) { std::cout \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; } catch (int a) { std::cout \u0026lt;\u0026lt; \u0026quot;int thrown \u0026quot; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::endl; } return 0; }  Ok, if you copy source code, compile and run it, you\u0026rsquo;ll see:\n$ g++ main.cpp -o throw $ ./throw MyException happened  This behaviour is predictable. Exception thrown and caught by catch (MyException \u0026amp;e). No special modifiers is presented.\nLets change example a little (throwing exception from what()):\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; class MyException { public: std::string what() { throw 10; return \u0026quot;MyException happened\u0026quot;; } }; int main(int argc, char **argv) { try { MyException a; throw a; } catch (MyException \u0026amp;e) { std::cout \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; std::endl; } return 0; }  Throwing exception from what() causes unhandled exception:\n$ ./throw terminate called after throwing an instance of 'int' Aborted (core dumped)  Usage of throw() in function declaration is considered as a bad idea. But in this particular situation it is allowed: what() returns additional description, it must not send any other exception, as there is no guarantee this exception will behandled. Restrict exceptions from what():\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; class MyException { public: std::string what() throw() { throw 10; return \u0026quot;MyException happened\u0026quot;; } }; int main(int argc, char **argv) { try { MyException a; a.what(); } catch (...) { std::cout \u0026lt;\u0026lt; \u0026quot;exception handled\u0026quot; \u0026lt;\u0026lt; std::endl; } return 0; }  Finally we get what we came from: this class is pretty like std::exception, isn\u0026rsquo;t it? throw() ensures no exceptions can be sent from show() function. So, compiler will fail? No! Compiler reports no errors. But an error occures in runtime:\n$ ./throw terminate called after throwing an instance of 'int' Aborted (core dumped)  There is a little information why the code have failed. No exception (even raised in functions called from show()) will pass through show() throw(). Error will appear only at runtime.\nSo, throw() is used to ensure no additional exceptions will be raised from show() function and will escape catch(). But in general case such behaviour is difficult to predict and is a bad practice. Try not to use throw() in function signature without high necessity. Try not to use throw with particular allowed exceptions (like throw(A, B)) in any situation. Standart std::exception is very good to derive your exceptions in huge amount of sutuations.\n","date":"2013-11-23","permalink":"http://localhost:1313/blog/2013/11/23/throw-in-function-signature-in-c-/","tags":["c++","exceptions"],"title":"throw() in function signature in C++"},{"content":"The very simple and common test program is to read bunch of strings from input file (let it be input.txt), sort them and write down to another file (output.txt). There is an implementation with small bug: it adds extra empty line. I\u0026rsquo;ve modified original code a bit, so now it works correctly (note: if have last empty line in the input, you will have an empty line in the output). Fixed code is provided below.\nsortstrings.cpp:\n#include \u0026lt;fstream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;iterator\u0026gt; int main(int argc, char **argv) { std::ifstream fin(\u0026quot;input.txt\u0026quot;); std::vector\u0026lt;std::string\u0026gt; array; while (true) { std::string s; getline(fin, s); if (fin.eof()) { break; } array.push_back(s); std::cout \u0026lt;\u0026lt; s \u0026lt;\u0026lt; std::endl; } fin.close(); std::sort(array.begin(), array.end()); std::ofstream fout(\u0026quot;output.txt\u0026quot;); std::copy(array.begin(), array.end(), std::ostream_iterator\u0026lt;std::string\u0026gt;(fout, \u0026quot;\\n\u0026quot;)); fout.close(); return 0; } ","date":"2013-11-19","permalink":"http://localhost:1313/blog/2013/11/19/sort-strings-from-file-in-c-/","tags":["c++","howto","snippet"],"title":"Sort strings from file in C++"},{"content":"Quicksort has $O(N\\log(N))$ computational complexity in best and average cases, $O(N^{2})$ for bad case. Extremely bad cases may be avoided by using randomized Quicksort.\nQucksort algorithm consists of three steps:\n Choose reference element called pivot (in randomized version pivot choise is random) Rearrange array so that all elements smaller than pivot are placed before the pivot in array, all elements bigger than pivot are placed after the pivot Call Quicksort for elements before the pivot and Quicksort for elements after the pivot recursively (stop if array size is one or less)  My implementation of Quicksort in C++ is provided below. quicksort.cpp:\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdlib\u0026gt; #include \u0026lt;algorithm\u0026gt; template \u0026lt;typename T\u0026gt; void printArray(T *array, size_t size) { for (size_t i = 0; i \u0026lt; size; ++i) { std::cout \u0026lt;\u0026lt; array[i] \u0026lt;\u0026lt; \u0026quot; \u0026quot;; } std::cout \u0026lt;\u0026lt; std::endl; } template \u0026lt;typename T\u0026gt; void quickSort(T *array, size_t left, size_t right) { size_t l = left; size_t r = right - 1; size_t size = right - left; if (size \u0026gt; 1) { T pivot = array[rand() % size + l]; while (l \u0026lt; r) { while (array[r] \u0026gt; pivot \u0026amp;\u0026amp; r \u0026gt; l) { r--; } while (array[l] \u0026lt; pivot \u0026amp;\u0026amp; l \u0026lt;= r) { l++; } if (l \u0026lt; r) { std::swap(array[l], array[r]); l++; } } quickSort(array, left, l); quickSort(array, r, right); } } int main(void) { size_t size = 21; int *array = new int[size]; for (int i = 0; i \u0026lt; size; ++i) { array[i] = (100.0 * rand()) / RAND_MAX; } printArray(array, size); quickSort(array, 0, size); printArray(array, size); delete [] array; return 0; } ","date":"2013-11-07","permalink":"http://localhost:1313/blog/2013/11/07/randomized-quicksort-implementation-in-c-/","tags":["cpp","quicksort","howto","snippet"],"title":"Randomized quicksort implementation in C++"},{"content":"Heapsort is one of the fastest sorting algorithms. The best and the worst cases for heapsort have same $O(n\\log(n))$ performance.\nAt first heapsort creates heap from data with buildHeap function. Heap is organized in linear array as follows. Every $i$-th element has two children: $(2i)$-th element and $(2i+1)$-th one. The biggest element of the array is placed on the top of the heap.\nAfter heap building top element is swapped with the latest in the array, then heap is rebuilt for the array with size decreased by one. These operations repeat till array size is bigger than one. Note that array indexes have to start from one for this implementation to work correctly (that is why I use size+1 for array size).\nMy implementation of heapsort is presented below. heapsort.cpp:\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdlib\u0026gt; #include \u0026lt;algorithm\u0026gt; template \u0026lt;typename T\u0026gt; void checkRootNode(T *array, size_t root, size_t size) { size_t left = 2*root; size_t right = 2*root + 1; if (left \u0026lt; size \u0026amp;\u0026amp; array[root] \u0026lt; array[left]) { std::swap(array[root], array[left]); checkRootNode(array, left, size); } if (right \u0026lt; size \u0026amp;\u0026amp; array[root] \u0026lt; array[right]) { std::swap(array[root], array[right]); checkRootNode(array, right, size); } } template \u0026lt;typename T\u0026gt; void buildHeap(T *array, size_t size) { for (size_t i=size/2; i\u0026gt;0; --i) { checkRootNode(array, i, size); } } template \u0026lt;typename T\u0026gt; void heapSort(T *array, size_t size) { while (size \u0026gt; 1) { std::swap(array[1], array[size-1]); checkRootNode(array, 1, --size); } } template \u0026lt;typename T\u0026gt; void printArray(T *array, size_t size) { for (size_t i=1; i \u0026lt; size; ++i) { std::cout \u0026lt;\u0026lt; array[i] \u0026lt;\u0026lt; ' '; } std::cout \u0026lt;\u0026lt; std::endl; } int main(void) { size_t size = 23; int *array = new int[size+1]; for (int i=1; i\u0026lt;size+1; ++i) { array[i] = (100.0*rand())/RAND_MAX; } printArray(array, size); buildHeap(array, size); heapSort(array, size); printArray(array, size); delete [] array; return 0; }  Results:\n[kenarius@cudasus]$ g++ heapsort.cpp [kenarius@cudasus]$ ./a.out 84 39 78 79 91 19 33 76 27 55 47 62 36 51 95 91 63 71 14 60 1 24 1 14 19 24 27 33 36 39 47 51 55 60 62 63 71 76 78 79 84 91 91 95 ","date":"2013-11-04","permalink":"http://localhost:1313/blog/2013/11/04/heapsort-implementation-in-c-/","tags":["cpp","heapsort","howto","snippet"],"title":"Heapsort implementation in C++"},{"content":"Previously I wrote about gengetopt tool to parse command line arguments. There was a line about application version.\nversion \u0026quot;13.10.25\u0026quot;  It is important to keep this line up to date every time you compile and deploy binary.\nI suggest to use Python script for this. Preliminaries: hg id -n returns local revision number, hg id -i returns global revision id. Combining date, local revision and global revision I generate version enough to determine source files used to create binary. For the following script gengetopt config must be placed in src/cmdline.ggo file. Script replaces version line with string \u0026ldquo;date local_revision:global_revision\u0026rdquo;. Listing for version.py:\n#!/usr/bin/env python from subprocess import check_output from datetime import datetime ggofile = open('src/cmdline.ggo', 'r') ggo = [line.strip('\\n') for line in ggofile.readlines() if not 'version' in line] ggofile.close() version = check_output(['hg','id','-n']).strip('\\n')+':'+check_output(['hg','id','-i']).strip('\\n') version = datetime.now().strftime('%Y.%m.%d') + ' ' + version ggo.insert(0, 'version \u0026quot;' + version + '\u0026quot;') ggofile = open('src/cmdline.ggo', 'w') print \u0026gt;\u0026gt;ggofile,'\\n'.join(ggo) ggofile.close()  Now just run version.py every time you want to build and deploy application binary (do not forget to regenerate parcer files with gengetopt: gengetopt -G -i cmdline.ggo in the directory with config).\n","date":"2013-11-02","permalink":"http://localhost:1313/blog/2013/11/02/set-application-version-in-gengetopt-config-based-on-mercurial-revision/","tags":["python","gengetopt","mercurial"],"title":"Set application version in gengetopt config based on Mercurial revision"},{"content":"Gengetopt is a tool for parsing command line arguments in C and C++ applications. It generates cmdline.c and cmdline.h files in pure C, which contain parser, helper functions, error handling and structure to store argument values. Arguments to be included in auto-generated file are defined in config. I usually gengetopt config file as cmdline.ggo. In this note I provide an example of gengetopt config file and arguments usage in code.\nHeader of config file contains information about version, app name and description. You can use the following template:\nversion \u0026quot;13.10.25\u0026quot; package \u0026quot;app\u0026quot; purpose \u0026quot;Sample application description. By John Doe \u0026lt;sample@example.com\u0026gt;\u0026quot;  Arguments are listed after header in the same config file. Even if no options given below the header, two default ones are defined: -h shows help message and -V shows app version string. You can specify long option name (in call it can be used as --long-option), short option name, option type and whether option is required.\nString option with long name filename and short name f, description String argument and it is required. Option can be called as -f myfile or --filename myfile.\noption \u0026quot;filename\u0026quot; f \u0026quot;String argument\u0026quot; string required  It is possible to define options that takes several values, separated by comma. The following opition takes exactly 3 arguments with type int:\noption \u0026quot;size\u0026quot; s \u0026quot;Optional argument, takes exactly 3 int values separated by commas\u0026quot; multiple(3) optional int  Option can take «one (two, etc) or more» arguments:\noption \u0026quot;array\u0026quot; a \u0026quot;Required argument, takes 1 or more args\u0026quot; multiple(1-) required int  It is possible not to specify short name:\noption \u0026quot;long-option\u0026quot; - \u0026quot;Option without short version\u0026quot; optional float  You can provide default value for an option. The default value is used if option is not used in app call.\noption \u0026quot;default-value\u0026quot; d \u0026quot;Argument with default value\u0026quot; optional float default=\u0026quot;0.003\u0026quot;  There is flags. If flag is provided in app call, it\u0026rsquo;s value triggered to opposite:\noption \u0026quot;console\u0026quot; c \u0026quot;Flag with default 'off'\u0026quot; flag off  The whole config file:\nversion \u0026quot;13.10.25\u0026quot; package \u0026quot;app\u0026quot; purpose \u0026quot;Sample application description. By John Doe \u0026lt;sample@example.com\u0026gt;\u0026quot; # Options option \u0026quot;filename\u0026quot; f \u0026quot;String argument\u0026quot; string required option \u0026quot;size\u0026quot; s \u0026quot;Optional argument, takes exactly 3 int values separated by commas\u0026quot; multiple(3) optional int option \u0026quot;array\u0026quot; a \u0026quot;Required argument, takes 1 or more args\u0026quot; multiple(1-) required int option \u0026quot;long-option\u0026quot; - \u0026quot;Option without short version\u0026quot; optional float option \u0026quot;default-value\u0026quot; d \u0026quot;Argument with default value\u0026quot; optional float default=\u0026quot;0.003\u0026quot; option \u0026quot;console\u0026quot; c \u0026quot;Flag with default 'off'\u0026quot; flag off  Arguments are used in source code via gengeopt_args_info structure defined in cmdline.h. Example:\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdlib\u0026gt; #include \u0026quot;cmdline.h\u0026quot; int main(int argc, char *argv[]) { gengetopt_args_info ai; if (cmdline_parser (argc, argv, \u0026amp;ai) != 0) { exit(1); } std::cout \u0026lt;\u0026lt; ai.filename_arg \u0026lt;\u0026lt; std::endl; if (ai.size_given) { std::cout \u0026lt;\u0026lt; ai.size_arg[0] \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; ai.size_arg[1] \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; ai.size_arg[2] \u0026lt;\u0026lt; std::endl; } for (int i=0; i\u0026lt;ai.array_given; ++i) { std::cout \u0026lt;\u0026lt; ai.array_arg[i] \u0026lt;\u0026lt; \u0026quot; \u0026quot;; } std::cout \u0026lt;\u0026lt; std::endl; if (ai.long_option_given) { std::cout \u0026lt;\u0026lt; ai.long_option_arg \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; ai.default_value_arg \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; ai.console_flag \u0026lt;\u0026lt; std::endl; return 0; }  And Makefile to make them all (you need gengetopt to be installed):\nAPPNAME = app OBJECTS = main.o cmdline.o CC = gcc CXX = g++ all: $(OBJECTS) $(CXX) $(OBJECTS) -o $(APPNAME) cmdline.o: cmdline.c $(CC) -c $\u0026lt; -o $@ main.o: main.cpp $(CXX) -c $\u0026lt; -o $@ cmdline.c: cmdline.ggo gengetopt --input=cmdline.ggo --include-getopt clean: rm -rf *.o $(APPNAME)  Place main.cpp, cmdline.ggo and Makefile in one folder and build this example.\nOutput samples:\n$ ./app -a 1,2,3,4,5,6 -f test -s 16,32,64 --long-option 0.4 -d 0.8 test 16 32 64 1 2 3 4 5 6 0.4 0.8 0  $ ./app -a 1 -f test -c test 1 0.003 1  $ ./app ./app: '--filename' ('-f') option required ./app: '--array' ('-a') option required  Have fun!\n","date":"2013-10-26","permalink":"http://localhost:1313/blog/2013/10/26/command-line-arguments-in-c-and-c-with-gengetopt/","tags":["howto","tutorial","gengetopt","cpp","c"],"title":"Command line arguments in C and C++ with gengetopt"},{"content":"Assymetric encryption is useful if you want to encrypt data at remote server via script. In case you use bash script for symmetric encryption job, you have to store password inside this script. So, if remote server is compromized, you will loose both the encrypted data and the key to decrypt it. Assymetric encryption allows you not to store decryption key at remote machine. So, data will be in safe even if server is hacked.\nAssymetric encryption is slow and cannot be applied for large files. The solution is to use hybrid symmetric-assymetric encryption for big data situation. It works as follows: big file is encrypted with symmetric algorythm with on the fly generated key. Key is stored in the file and encrypted with assymetric algorythm.\nBash scripts to encrypt and decrypt files are provided below. To simulate situation with local and remote machines, create local and remote folders side by side. Change directory to local folder, create public and private keys pair and copy public key (keynames are keyfile.key for private and keyfile.pub for public) to remote folder:\ncd local openssl genrsa -out keyfile.key 4096 openssl rsa -in keyfile.key -pubout -out keyfile.pub cp keyfile.pub ../remote/  Now change directory to remote folder. Create bash script encrypt.sh:\n#!/bin/bash file=$1 passfile=${file}_pwd pubkey=keyfile.pub openssl rand 256 \u0026gt; ${passfile} tar cz $file | openssl enc -aes-256-cbc -salt -out ${file}.enc -pass file:./${passfile} openssl rsautl -encrypt -pubin -inkey ${pubkey} -in ${passfile} -out ${passfile}.enc rm ${file} ${passfile} cp ${file}.enc ${passfile}.enc ../local  Make it executable:\nchmod +x ./encrypt.sh  Now you can create testfile with text \u0026ldquo;secret data\u0026rdquo; and encrypt it with script encrypt.sh. Resulting encrypted files will be copied to ../local folder.\necho \u0026quot;secret data\u0026quot; \u0026gt; testfile ./encrypt.sh testfile  Now change directory to local folder. Create bash script decrypt.sh:\n#!/bin/bash file=$1 passfile=${file%.enc}_pwd.enc privatekey=keyfile.key openssl rsautl -decrypt -inkey ${privatekey} -in ${passfile} -out ${passfile%.enc} openssl enc -d -aes-256-cbc -in ${file} -pass file:./${passfile%.enc} | tar xz rm ${file} ${passfile} ${passfile%.enc}  Make it executable:\nchmod +x ./decrypt.sh  Now decrypt testfile:\n./decrypt.sh testfile.enc  Decypted testfile will be placed into local directory.\n","date":"2013-10-12","permalink":"http://localhost:1313/blog/2013/10/12/hybrid-symmetric-asymmetric-encryption-for-large-files/","tags":["bash"],"title":"Hybrid symmetric-asymmetric encryption for large files"},{"content":"I used to utilize gnuplot for creation of plots with arbitrary data. The main problem was to postprocess data before plotting: I had to integrate postprocess into calculation code itself or to write additional script to do so. I\u0026rsquo;d like to provide an example of good-looking plotting with Python and matplotlib. Python has bataries included, so there will be no problem with preparation of data to be plotted.\nExample script plot_example.py:\n#~/usr/bin/env python #-*- coding: utf-8 -*- import matplotlib.pyplot as plt # set global settings def init_plotting(): plt.rcParams['figure.figsize'] = (8, 3) plt.rcParams['font.size'] = 10 plt.rcParams['font.family'] = 'Times New Roman' plt.rcParams['axes.labelsize'] = plt.rcParams['font.size'] plt.rcParams['axes.titlesize'] = 1.5*plt.rcParams['font.size'] plt.rcParams['legend.fontsize'] = plt.rcParams['font.size'] plt.rcParams['xtick.labelsize'] = plt.rcParams['font.size'] plt.rcParams['ytick.labelsize'] = plt.rcParams['font.size'] plt.rcParams['savefig.dpi'] = 2*plt.rcParams['savefig.dpi'] plt.rcParams['xtick.major.size'] = 3 plt.rcParams['xtick.minor.size'] = 3 plt.rcParams['xtick.major.width'] = 1 plt.rcParams['xtick.minor.width'] = 1 plt.rcParams['ytick.major.size'] = 3 plt.rcParams['ytick.minor.size'] = 3 plt.rcParams['ytick.major.width'] = 1 plt.rcParams['ytick.minor.width'] = 1 plt.rcParams['legend.frameon'] = False plt.rcParams['legend.loc'] = 'center left' plt.rcParams['axes.linewidth'] = 1 plt.gca().spines['right'].set_color('none') plt.gca().spines['top'].set_color('none') plt.gca().xaxis.set_ticks_position('bottom') plt.gca().yaxis.set_ticks_position('left') init_plotting() # plotting example data from math import sin from math import cos x = [0.31415*xi for xi in xrange(0,10)] y1 = [sin(xi) for xi in x] y2 = [cos(xi + 0.5) for xi in x] y3 = [cos(xi + 0.5) + sin(xi) for xi in x] # begin subplots region plt.subplot(121) plt.gca().margins(0.1, 0.1) plt.plot(x, y1, linestyle='-', marker='.', linewidth=1, color='r', label='sin') plt.plot(x, y2, linestyle='.', marker='o', linewidth=1, color='b', label='cos') plt.gca().annotate(u'point $\\\\frac{\\\\tau}{2}$', xy=(x[2], y1[2]), xycoords='data', xytext=(30, -10), textcoords='offset points', size=8, arrowprops=dict(arrowstyle='simple', fc='g', ec='none')) plt.xlabel(u'x label') plt.ylabel(u'y label') plt.title(u'First plot title') plt.gca().legend(bbox_to_anchor = (0.0, 0.1)) plt.subplot(122) plt.gca().margins(0.1, 0.1) plt.plot(x, y3, linestyle='--', marker='.', linewidth=1, color='g', label='sum') plt.gca().annotate(u'$y_x$', xy=(x[2], y3[2]), xycoords='data', xytext=(-30, -20), textcoords='offset points', size=8, arrowprops=dict(arrowstyle='simple', fc='orange', ec='none')) plt.xlabel(u'x label') plt.ylabel(u'y label') plt.title(u'Second plot title') plt.gca().legend(bbox_to_anchor = (0.0, 0.1)) # end subplots region # output resulting plot to file plt.tight_layout() plt.savefig('graph.png')  I\u0026rsquo;ve set all important parameters for me: font, size of font, width of different types of lines, titles, labels, so you can change them to fit yourself. PNG output can be changed to EPS or PDF ones.\nFirst part of script is an init function. It sets some global matplotlib parameters (so you do not need to edit your matplotlib rc file). You can edit parameters.\nSecond part is preparation of data to be plotted. You can replace it completely with your own code. For example, to load data from file.\nThird part is creating plots. You can add only one plot at figure (to do so, remove second plot and subplot statements). You can add more plots at one figure (change subplot accordingly. Three numbers are rows of plots, columns of plots and the plot number. For 2x2 plots use subplot(22x) where x is plot number.)\nResult: ","date":"2013-10-03","permalink":"http://localhost:1313/blog/2013/10/03/creation-of-paper-ready-plots-with-matlotlib/","tags":["matplotlib","python","howto","latex","plots"],"title":"Creation of paper-ready plots with matlotlib"},{"content":"I\u0026rsquo;d like to show how to use HPC part written on C++ with CUDA in Python code. So, every heavy part may be done on GPU with CUDA, all gluing tasks (with beautiful matplotlib plots) are done on CPU with Python.\nWe will use shared object, compiled from C++ CUDA code in Python. The only uncertain part here is conversation of types from «high-level» Python ones to «low-level» C++ ones. We will write application for parallel calculation of elementwise sum for two arrays.\nFirst, CUDA code. CUDA kernel cuda_sum_kernel is doing job on GPU, wrapper cuda_sum prepares arrays for GPU and frees memory after calculation is done. Note extern \u0026quot;C\u0026quot; line. It is important for correct function name in the compiled shared object later.\n#include \u0026lt;cuda.h\u0026gt; #include \u0026lt;cuda_runtime_api.h\u0026gt; __global__ void cuda_sum_kernel(float *a, float *b, float *c, size_t size) { size_t idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx \u0026gt;= size) { return; } c[idx] = a[idx] + b[idx]; } extern \u0026quot;C\u0026quot; { void cuda_sum(float *a, float *b, float *c, size_t size) { float *d_a, *d_b, *d_c; cudaMalloc((void **)\u0026amp;d_a, size * sizeof(float)); cudaMalloc((void **)\u0026amp;d_b, size * sizeof(float)); cudaMalloc((void **)\u0026amp;d_c, size * sizeof(float)); cudaMemcpy(d_a, a, size * sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(d_b, b, size * sizeof(float), cudaMemcpyHostToDevice); cuda_sum_kernel \u0026lt;\u0026lt;\u0026lt; ceil(size / 256.0), 256 \u0026gt;\u0026gt;\u0026gt; (d_a, d_b, d_c, size); cudaMemcpy(c, d_c, size * sizeof(float), cudaMemcpyDeviceToHost); cudaFree(d_a); cudaFree(d_b); cudaFree(d_c); } }  Compile it to *.so file with nvcc compiler:\n/usr/local/cuda/bin/nvcc -Xcompiler -fPIC -shared -o cuda_sum.so cuda_sum.cu  The last part is to use function cuda_sum from created cuda_sum.so file in Python script. Example (with comments):\nimport numpy as np import ctypes from ctypes import * # extract cuda_sum function pointer in the shared object cuda_sum.so def get_cuda_sum(): dll = ctypes.CDLL('./cuda_sum.so', mode=ctypes.RTLD_GLOBAL) func = dll.cuda_sum func.argtypes = [POINTER(c_float), POINTER(c_float), POINTER(c_float), c_size_t] return func # create __cuda_sum function with get_cuda_sum() __cuda_sum = get_cuda_sum() # convenient python wrapper for __cuda_sum # it does all job with types convertation # from python ones to C++ ones def cuda_sum(a, b, c, size): a_p = a.ctypes.data_as(POINTER(c_float)) b_p = b.ctypes.data_as(POINTER(c_float)) c_p = c.ctypes.data_as(POINTER(c_float)) __cuda_sum(a_p, b_p, c_p, size) # testing, sum of two arrays of ones and output head part of resulting array if __name__ == '__main__': size=int(1024*1024) a = np.ones(size).astype('float32') b = np.ones(size).astype('float32') c = np.zeros(size).astype('float32') cuda_sum(a, b, c, size) print c[:10]  Now you can desing the code above into full-featured Python module.\n","date":"2013-10-01","permalink":"http://localhost:1313/blog/2013/10/01/using-cuda-c-functions-in-python-via-.so-and-ctypes/","tags":["cuda","howto","c++","bash","python"],"title":"Using CUDA C++ functions in Python via `*.so` and ctypes"},{"content":"This Python script retrieves computer\u0026rsquo;s external IP address (using internet.yandex.ru) and emails message with new IP if IP has been changed since last check. BeautifulSoup module is needed, so install it if you have no installed version:\nsudo pip install beautifulsoup  Script:\n#!/usr/bin/env python from BeautifulSoup import BeautifulSoup import urllib2 import re import smtplib from email.mime.text import MIMEText logFile = '/var/log/ippywatchdog.log' request = urllib2.urlopen('http://internet.yandex.ru') soup = BeautifulSoup(request) yandexIpResponse = soup.find('div', {'class': 'b-info__item b-info__item_type_ip'}) ip=re.search('[0-9]+.[0-9]+.[0-9]+.[0-9]+', str(yandexIpResponse)).group(0) prevIp = ip try: with open(logFile,'r') as log: prevIp = log.readline() log.close() except IOError: pass if (ip != prevIp): for recipient in ['\u0026lt;recipient0\u0026gt;', '\u0026lt;recipient1\u0026gt;']: msg = MIMEText('New IP address of Server is ' + ip) msg['Subject'] = 'IP address of Server changed' msg['From'] = '\u0026lt;email\u0026gt;' server = smtplib.SMTP('smtp.yandex.ru', 587) server.ehlo() server.starttls() server.ehlo() server.login(msg['From'], '\u0026lt;email_password\u0026gt;') msg['To'] = recipient server.sendmail(msg['From'], msg['To'], msg.as_string()) server.quit() with open(logFile, 'w') as log: log.write(ip) log.close()  Replace \u0026lt;recipient0\u0026gt; and \u0026lt;recipient1\u0026gt; with emails which you want to receive warnings about IP change. You can add more recipients or leave the only one. Replace \u0026lt;email\u0026gt; and \u0026lt;email_password\u0026gt; with real email account and password (you need real account at ya.ru or similar email provider). SMTP server in the following code is configured for yandex mail.\nNow place script to /opt/ippywhatchdog.py, make it executable, add to cron.\nsudo -s mv ippywhatchdog.py /opt/ chmod +x /opt/ippywhatchdog.py crontab -e  crontab -e will open text editor with cron configuration. Add the following string to execute script every 5 minutes:\n*/5 * * * * /opt/ippywatchdog.py ","date":"2013-09-09","permalink":"http://localhost:1313/blog/2013/09/09/email-notification-if-ip-is-changed-with-python-and-cron/","tags":["python","howto","ip","cron","server"],"title":"Email notification if IP is changed with Python and cron"},{"content":"I often work on my netbook, so I prefer to use Sublime Text with Makefiles instead of full-featured IDEs. To automate build process I\u0026rsquo;ve constructed (with help of Vasily Picard and examples from the Internet) universal Makefile. It assumes the following structure of files.\nAll sources are placed in the src subdirectory. Intermediate object files are placed in obj subdirectory, it must be created before compilation. Resulting binary file is placed into bin subdirectory. If you use gengetopt as command-line arguments parcer, name ggo file as cmdline.ggo and *.c and *.h files will be updated automatically if ggo is changed.\nThe following makefile is set to use mpi compilers, include OpenGL, CUDA and GLUT libraries, and compile CUDA source code as well. Feel free to remove unnecessary fragments and to change application binary name (in the first line).\nAPPNAME := bin/app SOURCES := $(wildcard src/*.cpp src/*.cu src/*.c) OBJECTS := $(patsubst src%,obj%, $(patsubst %.cu,%.device.o, $(patsubst %.cpp,%.o, $(patsubst %.c,%.o, $(SOURCES))))) INCLUDE := -I/usr/local/cuda/include LIBPATH := -L/usr/local/cuda/lib64 LIBS := -lcudart -lGL -lglut FLAGS := -O3 -ffast-math -Wall -Werror -fopenmp CCFLAGS := $(FLAGS) CXXFLAGS := $(FLAGS) -std=c++0x GENCODE_FLAGS := -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 NVCCFLAGS := $(GENCODE_FLAGS) --compiler-options -fno-strict-aliasing -lineinfo -use_fast_math -Xptxas -dlcm=cg CC := mpicc CXX := mpicxx NVCC := /usr/local/cuda/bin/nvcc all: $(OBJECTS) $(CXX) $(CXXFLAGS) $(INCLUDE) $(OBJECTS) -o $(APPNAME) $(LIBPATH) $(LIBS) obj/cmdline.o: src/cmdline.c $(CC) -Wno-unused-but-set-variable -c $\u0026lt; -o $@ src/cmdline.c: src/cmdline.ggo gengetopt --input=src/cmdline.ggo --output-dir=src --include-getopt %.o: ../src/%.c $(CC) $(CCFLAGS) $(INCLUDE) -c $\u0026lt; -o $@ %.o: ../src/%.cpp $(CXX) $(CXXFLAGS) $(INCLUDE) -c $\u0026lt; -o $@ %.device.o: ../src/%.cu $(NVCC) $(NVCCFLAGS) -c $\u0026lt; -o $@ clean: rm -rf obj/* rm -f $(APPNAME) ","date":"2013-09-02","permalink":"http://localhost:1313/blog/2013/09/02/universal-simple-makefile/","tags":["howto","makefile"],"title":"Universal simple Makefile"},{"content":"This note describes installation of Bittorrent Sync on Ubuntu. Tutorial was tested on Ubuntu 12.04, but it must work for all Debian-based systems. Read full btsync manual for advanced information.\nDownload and install btsync Btsync is provided as single binary file. We will place it into /usr/bin directory. So, download archive with binary file, extract it, remove archive, move binary:\nwget http://btsync.s3-website-us-east-1.amazonaws.com/btsync_x64.tar.gz tar xf btsync_x64.tar.gz rm btsync_x64.tar.gz sudo mv btsync /usr/bin/btsync  Configure shared folder We will use configuration file instead of web interface. Create ~/.sync/config.json (for \u0026lt;home folder\u0026gt; for user username is /home/username) with content provided below. If you have several users you want to use btsync, create config in their home folders.\n{ \u0026quot;device_name\u0026quot;: \u0026quot;\u0026lt;computer name\u0026gt;\u0026quot;, \u0026quot;pid_file\u0026quot; : \u0026quot;\u0026lt;home folder\u0026gt;/.sync/btsync.pid\u0026quot;, \u0026quot;storage_path\u0026quot;: \u0026quot;\u0026lt;home folder\u0026gt;/.sync\u0026quot;, \u0026quot;listening_port\u0026quot; : 0, \u0026quot;check_for_updates\u0026quot; : true, \u0026quot;use_upnp\u0026quot; : true, \u0026quot;download_limit\u0026quot; : 0, \u0026quot;upload_limit\u0026quot; : 0, \u0026quot;lan_encrypt_data\u0026quot;: true, \u0026quot;shared_folders\u0026quot; : [ { \u0026quot;secret\u0026quot; : \u0026quot;\u0026lt;secret key\u0026gt;\u0026quot;, \u0026quot;dir\u0026quot; : \u0026quot;\u0026lt;dir path\u0026gt;\u0026quot;, \u0026quot;use_relay_server\u0026quot; : true, \u0026quot;use_tracker\u0026quot; : true, \u0026quot;use_dht\u0026quot; : false, \u0026quot;search_lan\u0026quot; : true, \u0026quot;use_sync_trash\u0026quot; : true } ] }  Init script Create file /etc/init.d/btsync with content (thanks to Mendel, you need to list users who will use btsync in BTSYNC_USERS variable, every user must have config file from previous section in home folder):\n#!/bin/sh ### BEGIN INIT INFO # Provides: btsync # Required-Start: $local_fs $remote_fs # Required-Stop: $local_fs $remote_fs # Should-Start: $network # Should-Stop: $network # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Multi-user daemonized version of btsync. # Description: Starts the btsync daemon for all registered users. ### END INIT INFO # Source: https://gist.github.com/MendelGusmao/5398362 # Replace with linux users you want to run BTSync clients for BTSYNC_USERS=\u0026quot;kenarius\u0026quot; DAEMON=/usr/bin/btsync start() { for btsuser in $BTSYNC_USERS; do HOMEDIR=`getent passwd $btsuser | cut -d: -f6` config=$HOMEDIR/.sync/config.json if [ -f $config ]; then echo \u0026quot;Starting BTSync for $btsuser\u0026quot; start-stop-daemon -b -o -c $btsuser -S -u $btsuser -x $DAEMON -- --config $config else echo \u0026quot;Couldn't start BTSync for $btsuser (no $config found)\u0026quot; fi done } stop() { for btsuser in $BTSYNC_USERS; do dbpid=`pgrep -fu $btsuser $DAEMON` if [ ! -z \u0026quot;$dbpid\u0026quot; ]; then echo \u0026quot;Stopping btsync for $btsuser\u0026quot; start-stop-daemon -o -c $btsuser -K -u $btsuser -x $DAEMON fi done } status() { for btsuser in $BTSYNC_USERS; do dbpid=`pgrep -fu $btsuser $DAEMON` if [ -z \u0026quot;$dbpid\u0026quot; ]; then echo \u0026quot;btsync for USER $btsuser: not running.\u0026quot; else echo \u0026quot;btsync for USER $btsuser: running (pid $dbpid)\u0026quot; fi done } case \u0026quot;$1\u0026quot; in start) start ;; stop) stop ;; restart|reload|force-reload) stop start ;; status) status ;; *) echo \u0026quot;Usage: /etc/init.d/btsync {start|stop|reload|force-reload|restart|status}\u0026quot; exit 1 esac exit 0  That\u0026rsquo;s all. Now make btsync executable, register init script with update-rc.d and start service. Issue as root:\ncd /etc/init.d/ chmod +x btsync update-rc.d btsync defaults service btsync start ","date":"2013-08-26","permalink":"http://localhost:1313/blog/2013/08/26/install-and-configure-btsync-in-ubuntu-12.04/","tags":["ubuntu","btsync","howto"],"title":"Install and configure btsync in Ubuntu 12.04"},{"content":"Installing dependencies Firstly you need to install webserver, php-related stuff and database server (we use PostgreSQL).\napt-get install -y php5-fpm nginx postgresql php5-pgsql  Now download and install Joomla (currently 3.1.5 is the latest). Please, update following lines with latest version if nescessary:\ncd /srv wget http://joomlacode.org/gf/download/frsrelease/18622/83487/Joomla_3.1.5-Stable-Full_Package.zip unzip Joomla_3.1.5-Stable-Full_Package.zip -d joomla chown -R www-data:www-data joomla  Database setup The only two things you need to do is to create user (joomla in example) and database (joomla in example). To do it under postgres user:\nsudo -u postgres -i createuser joomla --pwprompt --encrypted createdb joomla exit  Output should look like:\n$ createuser joomla --pwprompt --encrypted Enter password for new role: Enter it again: Shall the new role be a superuser? (y/n) n Shall the new role be allowed to create databases? (y/n) y Shall the new role be allowed to create more new roles? (y/n) n  nginx setup Create file joomla with content (you may want to adjust server_name and root):\n# vim /etc/nginx/sites-available/joomla server { listen 80; server_name joomla.lan; access_log /var/log/nginx/localhost.access.log; error_log /var/log/nginx/localhost.error.log; root /srv/joomla; index index.php index.html index.htm default.html default.htm; # Support Clean (aka Search Engine Friendly) URLs location / { try_files $uri $uri/ /index.php?$args; } # deny running scripts inside writable directories location ~* /(images|cache|media|logs|tmp)/.*\\.(php|pl|py|jsp|asp|sh|cgi)$ { return 403; error_page 403 /403_error.html; } location ~ \\.php$ { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include /etc/nginx/fastcgi.conf; } # caching of files location ~* \\.(ico|pdf|flv)$ { expires 1y; } location ~* \\.(js|css|png|jpg|jpeg|gif|swf|xml|txt)$ { expires 14d; } }  Enable site by creating link to config:\nln -s /etc/nginx/sites-available/joomla /etc/nginx/sites-enabled/  And add FastCGI options (create fastcgi.conf file):\n# vim /etc/nginx/fastcgi.conf fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param REQUEST_URI $request_uri; fastcgi_param DOCUMENT_URI $document_uri; fastcgi_param DOCUMENT_ROOT $document_root; fastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param GATEWAY_INTERFACE CGI/1.1; fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; fastcgi_param REMOTE_ADDR $remote_addr; fastcgi_param REMOTE_PORT $remote_port; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; fastcgi_param HTTPS $https; # PHP only, required if PHP was built with --enable-force-cgi-redirect fastcgi_param REDIRECT_STATUS 200;  hosts setup Now you need to point joomla.lan to 127.0.0.1 ip address. To do it, add line to /etc/hosts:\n{% codeblock%} 127.0.0.1 joomla.lan\n Now restart and go to http://joomla.lan","date":"2013-08-19","permalink":"http://localhost:1313/blog/2013/08/19/setting-up-joomla-3.1.5-with-postgresql-on-ubuntu-13.04/","tags":["ubuntu","server","joomla","postgres","howto"],"title":"Setting up Joomla 3.1.5 with PostgreSQL on Ubuntu 13.04"},{"content":"It is a good tone to check CUDA API errors while calling cudaMalloc() and other functions. It also helps to find floating bugs caused by hardware (lack of memory, etc). I provide below an adapted version of CudaSafeCall I found many weeks ago in the Internet. Simply remove #define CUDA_ERROR_CHECK in production if unneeded.\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;cuda.h\u0026gt; #define CUDA_ERROR_CHECK #define CudaSafeCall(error) __cudaSafeCall(error, __FILE__, __LINE__) inline void __cudaSafeCall(cudaError error, const char *file, const int line) { #ifdef CUDA_ERROR_CHECK if (error != cudaSuccess ) { std::cout \u0026lt;\u0026lt; \u0026quot;error: CudaSafeCall() failed at \u0026quot; \u0026lt;\u0026lt; file \u0026lt;\u0026lt; \u0026quot;:\u0026quot; \u0026lt;\u0026lt; line \u0026lt;\u0026lt; \u0026quot; with \\\u0026quot;\u0026quot; \u0026lt;\u0026lt; cudaGetErrorString(error) \u0026lt;\u0026lt; \u0026quot;\\\u0026quot;\u0026quot; \u0026lt;\u0026lt; std::endl; exit( -1 ); } #endif } int main(int argc, char **argv) { float *d_array; size_t N = 1024; CudaSafeCall(cudaMalloc((void **)\u0026amp;d_array, N*N*N*N)); CudaSafeCall(cudaFree(d_array)); return 0; } ","date":"2013-08-16","permalink":"http://localhost:1313/blog/2013/08/16/cudasafecall-application-snippet/","tags":["cuda","template","snippet"],"title":"CudaSafeCall application snippet"},{"content":"To enable tun device in OpenVZ containers tun module\n needs to be loaded in the host system (in my case CentOS 6.4) containter (in my case Ubuntu Server 12.04) must be allowed to use tun  I\u0026rsquo;ve grabbed container configuration from askbuntu.\nLoad tun after boot automatically Edit tun.modules:\n# vim /etc/sysconfig/modules/tun.modules #!/bin/sh /sbin/modprobe tun  Set permissions for tun.modules:\nchmod 755 /etc/sysconfig/modules/tun.modules  Reboot host system and test tun module loaded:\n$ lsmod | grep tun tun 15493 2  Edit container configuration Issue following commands in host terminal as root (change \u0026lsquo;101\u0026rsquo; to your container id):\nvzctl set 101 --devnodes net/tun:rw --save vzctl set 101 --devices c:10:200:rw --save vzctl set 101 --capability net_admin:on --save vzctl exec 101 mkdir -p /dev/net vzctl exec 101 mknod /dev/net/tun c 10 200 vzctl exec 101 chmod 600 /dev/net/tun  Now configured OpenVPN will work correctly.\n","date":"2013-08-10","permalink":"http://localhost:1313/blog/2013/08/10/enable-tun-for-openvz-ubuntu-12.04-containers-in-centos-6.4/","tags":["tun","server","openvz","vpn","ubuntu","centos"],"title":"Enable tun for OpenVZ Ubuntu 12.04 containers in CentOS 6.4"},{"content":"This howto is based on two sources: Official wiki and Amutu blog entry. In short, the main difficulty is in bridge network configuration: correct network configuration doesn\u0026rsquo;t work in CentOS 6.4 while NetworkManager is running. I compiled official documentation and fix found in Amutu blog here in one entry.\nI assume you have clean installed CentOS. I tried all on x32 hardware, so you may need to fix container type in container creation section if you use x64 CentOS. All commands below need to be issued as root.\nInstallation of OpenVZ wget -O /etc/yum.repos.d/openvz.repo http://download.openvz.org/openvz.repo rpm --import http://download.openvz.org/RPM-GPG-Key-OpenVZ yum install vzkernel vzctl vzquota  Add next two lines at the end of sysctl.conf:\n# vim /etc/sysctl.conf net.ipv4.icmp_echo_ignore_broadcasts=1 net.ipv4.conf.default.forwarding=1  Create bridge device (edit file ifcfg-vmbr0):\n# vim /etc/sysconfig/network-scripts/ifcfg-vmbr0 DEVICE=\u0026quot;vmbr0\u0026quot; BOOTPROTO=\u0026quot;static\u0026quot; IPV6INIT=\u0026quot;no\u0026quot; ONBOOT=\u0026quot;yes\u0026quot; TYPE=\u0026quot;Bridge\u0026quot; DELAY=0 IPADDR=[your host ip] NETMASK=255.255.255.0 GATEWAY=[your gateway]  Connect bridge to ethernet device (in my case it is eth0, so edit ifcfg-eth0):\n# vim /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=\u0026quot;eth0\u0026quot; ONBOOT=\u0026quot;yes\u0026quot; IPV6INIT=\u0026quot;no\u0026quot; TYPE=\u0026quot;Ethernet\u0026quot; BRIDGE=\u0026quot;vmbr0\u0026quot;  Allowing automated configuration of bridge for containers in vznet.conf:\n# vim /etc/vz/vznet.conf #!/bin/bash EXTERNAL_SCRIPT=\u0026quot;/usr/sbin/vznetaddbr\u0026quot;  Fixing NetworkManager issue chkconfig NetworkManager off chkconfig --levels 35 network on service NetworkManager stop service network restart  Reboot OpenVZ host system.\nCreation of container with bridged connection All commands below need to be issued as root. Create a container:\nvzctl create 101 --ostemplate ubuntu-12.04-x86 --config vswap-1g  Configure the container, type in terminal:\nvzctl set 101 --save --name container101 vzctl set 101 --save --onboot yes vzctl set 101 --save --hostname container101.domain.com vzctl set 101 --save --netif_add eth0,,,FE:FF:FF:FF:FF:FF vzctl set 101 --save --searchdomain domain.com vzctl set 101 --save --nameserver 8.8.8.8 --nameserver 8.8.4.4 vzctl set 101 --save --cpus 1 vzctl set 101 --save --ram 1G vzctl set 101 --save --swap 512M vzctl set 101 --save --diskspace 10G vzctl start 101 vzctl exec 101 passwd  Official wiki recommends to use big MAC.\nTo configure network in container, edit interfaces:\n# vim /vz/root/101/etc/network/interfaces auto lo eth0 iface lo inet loopback iface eth0 inet static address [your container ip] netmask 255.255.255.0 gateway [your gateway]  Enter container and reboot it:\nvzctl enter 101 reboot ","date":"2013-08-08","permalink":"http://localhost:1313/blog/2013/08/08/configuring-ubuntu-12.04-in-openvz-on-centos-6.4/","tags":["server","ubuntu","openvz","centos","howto"],"title":"Configuring Ubuntu 12.04 in OpenVZ on CentOS 6.4"},{"content":"Depends on server configuration, each OpenVPN client needs configuration file (client.conf for *nix and client.ovpn for windows), certificate authority (ca.crt), [optional] tls auth file (ta.key), user crt and key.\nTypical OpenVPN client configuration file looks like (ca and ta files in server subdirectory):\nclient remote \u0026lt;vpn server address\u0026gt; port 1194 proto udp dev tun dev-type tun ns-cert-type server reneg-sec 86400 comp-lzo yes verb 3 ca server/ca.crt cert \u0026lt;user crt\u0026gt; key \u0026lt;user key\u0026gt; tls-auth server/ta.key 1  The following is tested on Ubuntu 12.04, but it will work (maybe with some modifications) in other linux distributions. Create new subdirectory key-bundles in /etc/openvpn/easy-rsa directory. Place there the following script zip-key:\n#!/bin/bash NAME=$1 cd keys sed -s \u0026quot;s/^cert .*/cert ${NAME}.crt/g\u0026quot; -i client.conf sed -s \u0026quot;s/^key .*/key ${NAME}.key/g\u0026quot; -i client.conf cp client.conf client.ovpn zip -r ../key-bundles/${NAME}.zip client.conf client.ovpn server ${NAME}.crt ${NAME}.key cd -  You may need zip (sudo apt-get install zip) and make script executable (sudo chmod +x zip-key). I assume your VPN client configuration file is client.conf, ta.key and ca.crt are in /etc/openvpn/easy-rsa/keys/server directory. First and the only script argument is client key filename.\n","date":"2013-07-31","permalink":"http://localhost:1313/blog/2013/07/31/creating-zip-with-vpn-client-keys-and-configuration-files/","tags":["ubuntu","ubuntu 12.04","server","vpn","openvpn"],"title":"Creating Zip With VPN Client Keys and Configuration Files"},{"content":"It is possible to save configuration of ssh connection for later usage. For example, one had to type\nssh \u0026lt;username\u0026gt;@\u0026lt;ip address\u0026gt; -p \u0026lt;port\u0026gt; -i \u0026lt;path to key file\u0026gt;  every time one wants to connect to server.\nCreate ~/.ssh/config with following content:\nHost \u0026lt;name\u0026gt; Hostname \u0026lt;ip address\u0026gt; Port \u0026lt;port\u0026gt; User \u0026lt;username\u0026gt; IdentityFile \u0026lt;path to key file (if any)\u0026gt;  Now just type\nssh \u0026lt;name\u0026gt;  to get connected to the server.\n","date":"2013-07-12","permalink":"http://localhost:1313/blog/2013/07/12/configuration-of-hosts-for-convenient-ssh-connections/","tags":["ssh","linux","tips and tricks","console"],"title":"Configuration of hosts for convenient ssh connections"},{"content":"SLURM (Simple Linux Utility for Resource Management) — job scheduler and resource manager usually installed on supercomputers. For example, it runs on Lomonosov supercomputer in MSU, Moscow, Russia.\nUsually one physical or virtual computer (physical node) is one logical node is SLURM. If one physical node serve more than one logical nodes, it called «fat node». Fat nodes are needed in case you have a lot of memory at physical node or several GPUs on it. Sometimes fat nodes are convenient.\nSystem is Ubuntu 12.04 Server x64. We need additional configuration parameter, so SLURM will be built from the sources.\nPrerequisites Munge for nodes authentication and build-essential for building from sources are needed:\nsudo apt-get install -y libmunge-dev munge build-essential  Building SLURM Get, unpack and cd to slurm dir:\nwget http://www.schedmd.com/download/latest/slurm-2.5.7.tar.bz2 tar xvf slurm-2.5.7.tar.bz2 cd slurm-2.5.7/  Configure SLURM to enable fat nodes, make and install it:\n./configure --enable-multiple-slurmd make sudo make install  Configuring system We need to add user slurm and add him to group with the same name:\nsudo adduser slurm sudo adduser slurm slurm  Create munge key and start munge daemon:\nsudo /usr/sbin/create-munge-key sudo service munge start  Configuring SLURM Now create configuration file /usr/local/etc/slurm.conf:\nClusterName=ubuntu #\u0026lt; change this to your hostname ControlMachine=ubuntu #\u0026lt; change this to your host name SlurmUser=slurm SlurmctldPort=6817 AuthType=auth/munge StateSaveLocation=/tmp SlurmdSpoolDir=/tmp/slurmd%n/ SwitchType=switch/none MpiDefault=none SlurmctldPidFile=/var/run/slurmctld.pid SlurmdPidFile=/var/run/slurmd%n.pid ProctrackType=proctrack/pgid CacheGroups=0 ReturnToService=0 # TIMERS SlurmctldTimeout=300 SlurmdTimeout=300 InactiveLimit=0 MinJobAge=300 KillWait=30 Waittime=0 # SCHEDULING SchedulerType=sched/backfill SelectType=select/linear FastSchedule=1 # LOGGING SlurmctldDebug=3 SlurmdDebug=3 JobCompType=jobcomp/none # COMPUTE NODES # control node NodeName=ubuntu NodeAddr=127.0.0.1 Port=17000 State=UNKNOWN # each logical node is on the same physical node, so we need different ports for them # name node-[*] is arbitrary NodeName=node-0 NodeAddr=127.0.0.1 Port=17001 State=UNKNOWN NodeName=node-1 NodeAddr=127.0.0.1 Port=17002 State=UNKNOWN NodeName=node-2 NodeAddr=127.0.0.1 Port=17003 State=UNKNOWN NodeName=node-3 NodeAddr=127.0.0.1 Port=17004 State=UNKNOWN NodeName=node-4 NodeAddr=127.0.0.1 Port=17005 State=UNKNOWN # PARTITIONS # partition name is arbitrary PartitionName=cpu Nodes=node-[0-4] Default=YES MaxTime=INFINITE State=UP  Starting SLURM Start SLURM control daemon:\nsudo slurmctld -c  Start SLURM daemons for each logical node:\nsudo slurmd -c -N node-0 sudo slurmd -c -N node-1 sudo slurmd -c -N node-2 sudo slurmd -c -N node-3 sudo slurmd -c -N node-4  Check if everything is alright:\nsinfo  You must see that nodes are ready for work:\ncpu* up infinite 5 idle node-[0-4] ","date":"2013-06-18","permalink":"http://localhost:1313/blog/2013/06/18/ubuntu-server-12.04-slurm-2.5.7-fatnodes/","tags":["ubuntu","ubuntu server","server","slurm","fatnode"],"title":"Ubuntu Server 12.04 + Slurm 2.5.7 fatnodes"},{"content":"Default Drupal package in Ubuntu installs Apache, but I prefer nginx as a webserver. In this note I’ll describe steps necessary to get Drupal 7 work.\nAll variables in square brackets must be replaced by your names or passwords.\nSite will be available at url [sitename].\nInstalling packages Install all necessary packages:\nsudo apt-get install -y nginx php5-fpm php-apc php5-mysql mysql-client-core-5.5 mysql-server php5-gd  During the installation MySQL will ask you for root password. Rememer it, I will refer to it as [mysqlpwd] further.\nSet up MySQL Login to MySQL console:\nmysql -u root --password=[mysqlpwd]  and issue the following commands (create user, create database, allow user to work with database):\nCREATE USER '[dbuser]'@'localhost' IDENTIFIED BY '[dbpwd]'; CREATE DATABASE [dbname]; GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, INDEX, ALTER, LOCK TABLES, CREATE TEMPORARY TABLES ON `[dbname]`.* TO '[dbuser]'@'localhost' IDENTIFIED BY '[dbpwd]'; FLUSH PRIVILEGES; EXIT  Set up nginx Here we will make a configurational file for nginx.\nAs create file in sites-available directory with content:\nserver { listen 80; server_name [sitename]; access_log /var/log/[sitename].access.log; error_log /var/log/[sitename].error.log; root /srv/[sitename]; index index.php; location / { try_files $uri $uri/ /index.php; } location = /favicon.ico { empty_gif; } location ~ \\.php$ { include /etc/nginx/fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; } }  and add link for nginx to enable site:\nsudo ln /etc/nginx/sites-available/[sitename] /etc/nginx/sites-enabled/[sitename] sudo service nginx restart  Set up Drupal We will store Drupal in folder in /srv. Issue following commands in bash:\nsudo -s cd /srv wget http://ftp.drupal.org/files/projects/drupal-7.22.tar.gz tar xvf drupal-7.22.tar.gz mv drupal-7.22 [sitename] chown -R www-data:www-data [sitename] exit ","date":"2013-04-28","permalink":"http://localhost:1313/blog/2013/04/28/ubuntu-server-12.04-drupal-7-nginx-mysql/","tags":["drupal","nginx","mysql","server","ubuntu"],"title":"Ubuntu Server 12.04 + Drupal 7 + nginx + MySQL"},{"content":"You can record your screen using only command line in Linux. Workflow will look like: Create a bunch of screenshots -\u0026gt; Crop screenshots -\u0026gt; Make a movie from images.\nMaking screenshots scrot is command line screen capturing tool. It’s basic usage is very simple:\n$ scrot  or\n$ scrot \u0026lt;filename\u0026gt;.png  if you want to specify output filename.\nLet’s write script, which captures screen every 0.5 seconds and write result to screenshots/00000N.png (filename with leading zeros):\n#!/bin/bash t=0 while true; do scrot screenshots/`printf \u0026quot;%06g\\n\u0026quot; $t`.png sleep 0.5 t=`expr $t + 1` done exit 0  Cropping screenshots We will use magrify utility from ImageMagick package:\n$ for file in $(ls); do mogrify -crop \u0026lt;width\u0026gt;x\u0026lt;height\u0026gt;+\u0026lt;x_shift\u0026gt;+\u0026lt;y_shift\u0026gt; ${file}; done  You can determine width, height, x_shift, y_shift values by adjusting rectangular selection tool in GIMP or in any image viewer.\nCreating movie from images We will use ffmpeg for it. Here is command:\nffmpeg -qscale 1 -r 20 -b 9600 -i %06d.png \u0026lt;output_file\u0026gt;.mp4  ffmpeg is no longer supported in Ubuntu 14.04, you may use avconv:\navconv -qscale 1 -r 20 -b 9600 -i %06d.png \u0026lt;output_file\u0026gt;.mp4 ","date":"2013-01-23","permalink":"http://localhost:1313/blog/2013/01/23/universal-screen-capturing-with-scrot-imagemagick-and-ffmpeg/","tags":["ffmpeg","bash","screen capture","scrot"],"title":"Universal screen capturing with scrot, imagemagick and ffmpeg"},{"content":"In i3 window manager by default Nautilus actually opens two windows: Desktop window and Nautilus itself. The former can’t be closed by the default shortcut $Mod+Shift+Q.\nTo get rid of unwanted window, set desktop.background and show-desktop-icons to false by typing:\n$ gsettings set org.gnome.desktop.background show-desktop-icons false ","date":"2012-11-08","permalink":"http://localhost:1313/blog/2012/11/08/get-rid-of-desktop-window-while-launching-nautilus-in-i3/","tags":["i3","nautilus","ubuntu","ubuntu 12.04"],"title":"Get rid of Desktop window while launching Nautilus in i3"},{"content":"Pcap files are pocket capture files. They usually contain raw log of network connections and packets. It is the most popular format and it available in almost all network analysis tool.\nTo play around *.pcap, you have to get such file somehow. There are two opposite ways: to generate it by yourself or to pick a ready one. To generate it by yourself, you can use wireshark or tcpdump in terminal:\ntcpdump -w capture.pcap -i eth1  replace capture.pcap with desired output filename, -i eth1 indicates the interface for the logging to be done.\nAs soon as your *.pcap is created, it must be parsed for valuable data. Wireshark fits this task but let’s focuse on terminal utilities. I’ve found four ones, but I’m sure there is much more of them.\ntpick tcpick is able to capture network traffic, store data in different files for each connection and trace stored files. Colorful output in terminal is really neat.\nReading *.pcap file:\ntcpick -C -r capture.pcap  tshark Wireshark has a terminal twin names tshark. Latter is useful on old computers, for scripting and more convenient for console-boys. Can capture traffic and analyze captured files as well.\nReading *.pcap file with specified fields to display:\ntshark -n -r capture.pcap -T fields -e ip.dst_host -e frame.time_delta  tcptrace tcptrace is created for analysis of captured files. Has many options.\nReading *.pcap file:\ntcptrace --tsv -xHTTP -f''port=80'' -btn capture.pcap  tcpdump tcpdump was already mentioned as a tool for capturing traffic to pcap-file. It also can be used as analyser.\nReading *.pcap file:\ntcpdump -ttttnr capture.pcap ","date":"2012-11-03","permalink":"http://localhost:1313/blog/2012/11/03/tools-for-tracing-a-pcap-file-in-linux-bash/","tags":["pcap","tcpdump","tpick","tshark","tcptrace","bash","linux"],"title":"Tools for tracing a pcap file in linux bash"},{"content":"du (disk usage) utility in linux bash summarizes disk usage of each directory or file. By default, it outputs only directories. Just enter some dir and type\n$ du ./  But if ./ has many subdirectories, output will be too long. And it is unsorted. The stated in the title task can be achieved by piping.\nSort output by size Cut the first line, it is size of the ./ dir as sum of other sizes Use \u0026ldquo;—human-readable\u0026rdquo; in du or divide by 1024 to get kbytes, mbytes, etc. I divide by 1000 to get results close to nautilus ones.\nThe resulting command:\n$ du -b --max-depth=1 | sort -nr | sed -n '2,4p' | awk '{print $1/1000^3\u0026quot; Gb\\t\u0026quot; $2}' ","date":"2012-11-01","permalink":"http://localhost:1313/blog/2012/11/01/show-n-biggest-directories-in-linux-bash/","tags":["du","bash","linux","terminal","awk","sed"],"title":"Show N biggest directories in linux bash"},{"content":"It’s quite an academic task, but anyway useful sometimes. I’ve collected different ways to do it in terminal in linux. Some of them work with UTF-8 characters (some it will toggle case for \u0026ldquo;й\u0026rdquo;, \u0026ldquo;ё\u0026rdquo; and so on. It will not in general handle special ligatures, such as \u0026ldquo;ß\u0026rdquo;\u0026quot; and \u0026ldquo;ﬁ\u0026rdquo;.)\nWays are: sed, perl, python, awk, tr, bash, dd.\nUsing sed Works with UTF-8 characters.\nIt is quite straightforward and allows to add custom rules easily. For example, I’ve added special handling for ligatures \u0026ldquo;ß\u0026rdquo;\u0026quot; and \u0026ldquo;ﬁ\u0026rdquo;. I should note that conversion SS -\u0026gt; ß is not correct in general. So you may want to remove it.\n$ echo ''Wie hйЮёßen Sieﬁ тест'' | sed ''s/.*/\\U\u0026amp;/;s/ß/SS/g;s/ﬁ/FI/g'' WIE HЙЮЁSSEN SIEFI ТЕСТ $ echo ''WIE HЙЮЁSSEN SIEFI ТЕСТ'' | sed ''s/ß/SS/g;s/ﬁ/FI/g;s/.*/\\L\u0026amp;/'' wie hйюёssen siefi тест  Using perl Doesn’t work with UTF-8 characters.\nI’m not a perl-ninja, may be there is a more efficient way. But it works.\n$ echo ''Wie hйЮёßen Sieﬁ тест'' | perl -ne ''print uc($_)'' WIE HйЮёßEN SIEﬁ тест $ echo ''WIE HЙЮЁSSEN SIEFI ТЕСТ'' | perl -ne ''print lc($_)'' wie hЙЮЁssen siefi ТЕСТ  Using python Doesn’t work with UTF-8 characters.\nPython nowadays sometimes said to be replacement for perl. It can not convert Cyrillic letters (UTF-8) too.\n$ echo ''Wie hйЮёßen Sieﬁ тест'' | python -c \u0026quot;import sys; [sys.stdout.write(arg.upper()) for arg in raw_input()]; print \u0026quot;\\n\u0026quot;\u0026quot; WIE HйЮёßEN SIEﬁ тест $ echo ''WIE HЙЮЁSSEN SIEFI ТЕСТ'' | python -c \u0026quot;import sys; [sys.stdout.write(arg.lower()) for arg in raw_input()]; print \u0026quot;\\n\u0026quot;\u0026quot; wie hЙЮЁssen siefi ТЕСТ  Using awk Doesn’t work with UTF-8 characters in mawk, works with UTF-8 characters in gawk.\nDefault awk in Ubuntu 12.04 is mawk. To get UTF-8 support you have to install gawk and use it.\n$ echo ''Wie hйЮёßen Sieﬁ тест'' | gawk ''{for (i=1; i\u0026lt;=NF; i++) printf toupper($i)\u0026quot; \u0026quot;} END {print \u0026quot;\u0026quot;}'' WIE HЙЮЁßEN SIEﬁ ТЕСТ $ echo ''WIE HЙЮЁSSEN SIEFI ТЕСТ'' | gawk ''{for (i=1; i\u0026lt;=NF; i++) printf tolower($i)\u0026quot; \u0026quot;} END {print \u0026quot;\u0026quot;}'' wie hйюёssen siefi тест  Using tr Doesn’t work with UTF-8 characters.\nIt works with current locale. But I work in us locale and my native language is Russian.\nIt is the easiest way I believe. It also fits the purpose of tr — to translate and delete characters. It is possible to add custom rules such as “tr ‘ё’ ‘Ё’\u0026quot;, but it caused new strange symbols to appear in the output.\n$ echo ''Wie hйЮёßen Sieﬁ тест'' | tr ''[:lower:]'' ''[:upper:]'' WIE HйЮёßEN SIEﬁ тест $ echo ''WIE HЙЮЁSSEN SIEFI ТЕСТ'' | tr ''[:upper:]'' ''[:lower:]'' wie hЙЮЁssen siefi ТЕСТ  Using bash Doesn’t work with UTF-8 characters.\nWarning! It’s weird way for converting strings, but a good way to convert variables in bash scripts.\n$ export a=''Wie hйЮёßen Sieﬁ тест'' ; echo ${a^^} WIE HйЮёßEN SIEﬁ тест $ export a=''WIE HЙЮЁSSEN SIEFI ТЕСТ'' ; echo ${a,,} wie hЙЮЁssen siefi ТЕСТ  Using dd Doesn’t work with UTF-8 characters.\nThe bad news it outputs more information than only toggled string. Just for collection.\n$ echo ''Wie hйЮёßen Sieﬁ тест'' | dd conv=ucase WIE HйЮёßEN SIEﬁ тест 0+1 records in 0+1 records out 32 bytes (32 B) copied, 0.000124458 s, 257 kB/s $ echo ''WIE HЙЮЁSSEN SIEFI ТЕСТ'' | dd conv=lcase wie hЙЮЁssen siefi ТЕСТ 0+1 records in 0+1 records out 31 bytes (31 B) copied, 7.913e-05 s, 392 kB/s  Using php Doesn’t work with UTF-8 characters.\nPHP can be used as scripting language for general purposes with php-cli.\n$ echo ''Wie hйЮёßen Sieﬁ тест'' | php -r \u0026quot;print strtoupper(fgets(STDIN));\u0026quot; WIE HйЮёßEN SIEﬁ тест $ echo ''WIE HЙЮЁSSEN SIEFI ТЕСТ'' | php -r \u0026quot;print strtolower(fgets(STDIN));\u0026quot; wie hЙЮЁssen siefi ТЕСТ ","date":"2012-10-31","permalink":"http://localhost:1313/blog/2012/10/31/toggling-string-case-in-linux-bash/","tags":["sed","awk","python","bash","tr","dd","perl","terminal","linux"],"title":"Toggling string case in linux bash"},{"content":"This howto is based on a great guide with modifications. All settings are made for server domain hg.kenarius.org. You can replace it with your one easily.\nPreparation Ubuntu Update Ubuntu with the commands:\nsudo apt-get update sudo apt-get upgrade  Install pip and virtualenv with the commands:\nsudo apt-get install python-pip sudo pip install virtualenv  Nginx Install nginx:\nsudo apt-get install nginx  Add create ssl certificates:\nsudo openssl req -new -x509 -days 9999 -nodes -out host.pem -keyout host.key  Create /etc/nginx/ssl.conf file:\n# Sert generation: # openssl req -new -x509 -days 9999 -nodes -out cert.pem -keyout cert.key ssl on; ssl_protocols SSLv3 TLSv1; ssl_certificate /etc/nginx/ssl/host.pem; ssl_certificate_key /etc/nginx/ssl/host.key;  Installing RhodeCode Install Python sources:\nsudo apt-get install python-dev  Create the base directory and temporarily give yourself ownership:\nsudo mkdir /srv/hg.kenarius.org sudo su cd /srv/hg.kenarius.org  Create the data directory, virtual environment, and install RhodeCode:\nvirtualenv --no-site-packages /srv/hg.kenarius.org/venv source /srv/hg.kenarius.org/venv/bin/activate (venv) pip install pastescript (venv) easy_install rhodecode  Create directories and the production configuraton:\nmkdir /home/repository mkdir /srv/hg.kenarius.org/data cd /srv/hg.kenarius.org/data (venv) paster make-config RhodeCode production.ini  Generate the RhodeCode database and create the initial admin account:\n(venv) paster setup-rhodecode production.ini  Starting RhodeCode on boot Create start.sh in /srv/hg.kenarius.org:\n#!/bin/bash # run this as the rhodecode user! WDIR=/srv/hg.kenarius.org VIRTUALENV_DIR=/srv/hg.kenarius.org/venv source $VIRTUALENV_DIR/bin/activate cd $WDIR paster serve $WDIR/data/production.ini 1\u0026gt; debug.log 2\u0026gt; error.log  Create rhodecode in /etc/init.d:\n#!/bin/sh -e ######################################## #### THIS IS A DEBIAN INIT.D SCRIPT #### ######################################## ### BEGIN INIT INFO # Provides: rhodecode # Required-Start: $all # Required-Stop: $all # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: starts instance of rhodecode # Description: starts instance of rhodecode using start-stop- daemon ### EN D INIT INFO APP_NAME=\u0026quot;rhodecode\u0026quot; APP_HOMEDIR=\u0026quot;hg.kenarius.org\u0026quot; APP_PATH=\u0026quot;/srv/$APP_HOMEDIR\u0026quot; CONF_NAME=\u0026quot;data/production.ini\u0026quot; PID_PATH=\u0026quot;$APP_PATH/$APP_NAME.pid\u0026quot; LOG_PATH=\u0026quot;$APP_PATH/$APP_NAME.log\u0026quot; PYTHON_PATH=\u0026quot;/srv/$APP_HOMEDIR/venv\u0026quot; RUN_AS=\u0026quot;www-data\u0026quot; DAEMON=\u0026quot;$PYTHON_PATH/bin/paster\u0026quot; DAEMON_OPTS=\u0026quot;serve --daemon \\ --user=$RUN_AS \\ --group=$RUN_AS \\ --pid-file=$PID_PATH \\ --log-file=$LOG_PATH $APP_PATH/$CONF_NAME\u0026quot; start() { echo \u0026quot;Starting $APP_NAME\u0026quot; PYTHON_EGG_CACHE=\u0026quot;/tmp\u0026quot; start-stop-daemon -d $APP_PATH \\ --start --quiet \\ --pidfile $PID_PATH \\ --user $RUN_AS \\ --exec $DAEMON -- $DAEMON_OPTS } stop() { echo \u0026quot;Stopping $APP_NAME\u0026quot; start-stop-daemon -d $APP_PATH \\ --stop --quiet \\ --pidfile $PID_PATH || echo \u0026quot;$APP_NAME - Not running!\u0026quot; if [ -f $PID_PATH ]; then rm $PID_PATH fi } case \u0026quot;$1\u0026quot; in start) start ;; stop) stop ;; restart) echo \u0026quot;Restarting $APP_NAME\u0026quot; ### stop ### stop wait ### start ### start ;; *) echo \u0026quot;Usage: $0 {start|stop|restart}\u0026quot; exit 1 esac  Allow to execute the script:\ncd /etc/init.d chmod +x rhodecode sudo ./rhodecode-init.d.sh start  Install the script:\nsudo update-rc.d rhodecode defaults 90  Test the script once more:\nsudo service rhodecode start sudo service rhodecode stop  Adding Nginx as a front-end for SSL Create /etc/nginx/proxy.conf file:\nproxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Url-Scheme $scheme; proxy_set_header X-Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Proxy-host $proxy_host; client_max_body_size 400m; client_body_buffer_size 128k; proxy_buffering off; proxy_connect_timeout 7200; proxy_send_timeout 7200; proxy_read_timeout 7200; proxy_buffers 8 32k;  Create /etc/nginx/sites-enabled/hg.kenarius.org file (assuming you already have ssl settings for nginx):\nserver { listen 80; server_name hg.kenarius.org; rewrite ^ https://$server_name$request_uri? permanent; } server { listen 443; server_name hg.kenarius.org; access_log /var/log/nginx/rhodecode.access.log; error_log /var/log/nginx/rhodecode.error.log; include /etc/nginx/proxy.conf; include /etc/nginx/ssl.conf; location / { try_files $uri @rhode; } location @rhode { proxy_pass http://127.0.0.1:5000; } }  Reload nginx settings:\nnginx -s reload ","date":"2012-10-29","permalink":"http://localhost:1313/blog/2012/10/29/setting-up-rhodecode-on-ubuntu-12.04/","tags":["rhodecode","mercurial","ubuntu 12.04","ubuntu server","howto","server"],"title":"Setting up RhodeCode on Ubuntu 12.04"},{"content":"AWK is an acronym of first letters of its authors (Aho, Weinberger and Kernighan). It is a data-manipulating scripting language with huge possibilities. There are several implementations of it: awk is a canonical one, nawk (new awk), mawk (default in Ubuntu 12.04), gawk is GNU awk. I recommend latter one, because it works correct with unicode symbols in example:\n$ echo юникод | gawk \u0026quot;{res = toupper(\\$1); print res;}\u0026quot; ЮНИКОД  Basic usage Most useful feature is writing script files to be loaded in awk later. One can execute script file by\ngawk [options] -f script_file.awk input_file  If there is no input file awk will read standard input stream.\nLet’s take a look at an example. It reads input stream, writes down first argument to history, increases counter by 1 and prints \u0026ldquo;”. Code of script.awk:\n#!/usr/bin/gawk -f # BEGIN block executes only once after running awk BEGIN { print \u0026quot;\\nBegin printing args\\n\u0026quot;; i = 0; } # Main block executes for every argument { i++; history[i] = $1; print i, $1; if ($1 == 0) exit(0); } # END block executes only once at finishing awk END { print \u0026quot;\\nArguments were: \u0026quot;; for (n=1; n\u0026lt;=i; ++n) print history[n],\u0026quot; \u0026quot;; print \u0026quot;\\nEnd printing args\\n\u0026quot; }  Then, make script executable and run it:\n$chmod +x ./script.awk $./script.awk  Output will be like (\u0026ldquo;one\u0026rdquo;-enter, “cat\u0026rdquo;-enter, “dog\u0026quot;-enter, “0\u0026quot;-enter):\nBegin printing args one 1 one cat 2 cat dog 3 dog 0 4 0 Arguments were: one cat dog 0 End printing args  Awk can be launched with script inline:\ngawk [options] ''script_text'' file(s)  Example counts “block\u0026quot; words in code listed above:\nawk \u0026quot;BEGIN{blocks=0} /block/{blocks++} END{ print blocks}\u0026quot; script.awk  Where /regular expression/ controls whether block after it will be executed.\nUser-defined functions In awk user-defined functions can be added as follows:\n#!/usr/bin/gawk -f # returns sum of numbers function sum(a, b, c) { res = a + b + c; return res; } # main program, for testing { print sum($1, $2, $3); } ","date":"2012-10-25","permalink":"http://localhost:1313/blog/2012/10/25/awk-a-powerful-tool-for-programmer/","tags":["awk","programmer tools","console"],"title":"AWK: a powerful tool for programmer"},{"content":"We all do backups. This note is about doing them on Ubuntu 12.04.\nTasks:\n archive important folders dump mysql databases upload all to yandex.disk (online web storage with 10GB space) delete old backups  I’ll save only backups for last five days.\nArchiving There are many different backup tools, see wiki list. I’ve chosen DAR.\nOne can install it in Ubuntu 12.04 by typing\n# apt-get install dar  It is a console utility and it can be confusing for beginner. Here is great short how-to with explanations.\nI will perform full backups every day. For incremental ones read manual.\nI need to backup /srv folder, so my command is:\ndar -m 256 -z -s 600M -D -R /srv -c `date -I`_data -Z \u0026quot;*.gz\u0026quot; -Z \u0026quot;*.bz2\u0026quot; -Z \u0026quot;*.zip\u0026quot; -Z \u0026quot;*.png\u0026quot;  It creates file currentdate_data.X.dar, for example 2012-08-30_data.1.dar, with a backup. If archive is bigger than 600M (-s 600M), it splits in two slices. X in the filename represents slice number. For the full description read how-to.\nDumping MySQL Dumping MySQL is performed by mysqldump utility. You can list your databases in MySQL by entering into console with\nmysql -uroot -ppassword  and type there\nSHOW DATABASES;  I have drupal database I want to backup. So, I type:\nmysqldump -u root -ppassword drupal \u0026gt; `date -I`_drupal.mysqldump  It creates file with all necessary stuff to create the same table from nothing.\nUploading Yandex.Disk can be accessed by WebDAV. Install vebdavfs2:\n# apt-get install davfs2  Then edit /etc/davfs2/secrets. Just add line with address, login and password:\nhttps://webdav.yandex.ru username@yandex.ru \u0026quot;userpass\u0026quot;  Now you cat mount yandex.disk as an ordinary drive to folder /mount/yandex:\nmount -t davfs https://webdav.yandex.ru /media/yandex  Now it is possible to store backups in cloud.\nOld files can be removed by:\nrm `ls *.dar | head -n -5`  It leaves only last five backups.\nAdding to cron All commands from above in one script backup.sh:\n#!/bin/bash mount -t davfs https://webdav.yandex.ru /media/yandex cd /media/yandex/cudacer dar -m 256 -z -s 600M -D -R /srv -c `date -I`_data -Z \u0026quot;*.gz\u0026quot; -Z \u0026quot;*.bz2\u0026quot; -Z \u0026quot;*.zip\u0026quot; -Z \u0026quot;*.png\u0026quot; rm `ls *.dar | head -n -5` mysqldump -u root -p\u0026lt;password\u0026gt; \u0026lt;dbname\u0026gt;l \u0026gt; `date -I`_drupal.mysqldump rm `ls *.mysqldump | head -n -5`  Run it every day at 1am. Open cron tasks\n# crontab -e  and paste there line:\n0 1 * * * /home/kenarius/backup.sh  Now you have backups.\n","date":"2012-08-30","permalink":"http://localhost:1313/blog/2012/08/30/daily-backups-files-mysql-to-yandex.disk-in-ubuntu-12.04/","tags":["backup","ubuntu","yandex.disk","server"],"title":"Daily backups (files + mysql) to yandex.disk in Ubuntu 12.04"},{"content":"After moving to i3 I’ve installed PCManFM as GUI file manager. To fix missing icons one have to define icon theme. These instructions are tested on Ubuntu 12.04, but it must work with other distros.\nInstall icon theme:\nsudo apt-get install tango-icon-theme*  To apply theme, create .gtkrc-2.0 file in home directory:\n$ cat ~/.gtkrc-2.0 gtk-icon-theme-name = \u0026quot;Tango\u0026quot;  After this icons will be enabled.\n","date":"2012-08-24","permalink":"http://localhost:1313/blog/2012/08/24/fixing-missing-icons-in-pcmanfm/","tags":["linux","ubuntu","ubuntu 12.04","PCManFM"],"title":"Fixing missing icons in PCManFM"},{"content":"Glue several png’s into one png [1]+[2]+[3]+[4] = [[1][2][3][4]] with montage from ImageMagick:\nmontage -geometry +1+1 -tile 4x1 image*.png final.png ","date":"2012-07-18","permalink":"http://localhost:1313/blog/2012/07/18/montage-png-into-single-one/","tags":["bash","montage","imagemagick","png","snippet"],"title":"Montage png into single one"},{"content":"Blender is a free software for 3D graphics. In old virsions many operations were binded to hotkeys, so it was believed that Blender is very hard to master. Now it has more userfriendly interface with button in addition to hotkeys.\nOne of the most useful features of Blender is scripting. Below I provide python script for drawing molecules with cylinders and spheres.\nCommand to draw a sphere:\nbpy.ops.mesh.primitive_uv_sphere_add()  To draw a cylinder, you need to specify cylinder center and rotation. Rotation is described via rotation axis and rotation angle.\nTrivial cylinder after creation is aligned with Z axis: z = (0,0,1). If you need to connect two points r1 and r2 with cylinder, its center coordinate is r3 = (r1+r2)/2. Cylinder must be aligned with z_desired = (r1-r2).normalized(), so rotation axis is rot_axis = z.cross(z_desired) and angle angle = acos(z.dot(z_desired)).\nWrapping up, code:\nfrom math import degrees, acos from mathutils import Vector spheres = (Vector((2,3,3)),Vector((1,1,2)),Vector((2,3,4)),Vector((4,5,3))) edges = ((0,1),(1,2),(2,3)) for i in range(0, len(spheres)): r1 = spheres[i] bpy.ops.mesh.primitive_uv_sphere_add(location=(r1.x, r1.y, r1.z)) for i in range(0,len(edges)): r1 = spheres[edges[i][0]] r2 = spheres[edges[i][1]] r3 = (r1+r2)/2 z = Vector((0,0,1)) z_desired = (r1-r2).normalized() rot_axis = z.cross(z_desired) angle = acos(z.dot(z_desired)) bpy.ops.mesh.primitive_cylinder_add(radius=0.3, depth=(r2-r1).length,location=(r3.x,r3.y,r3.z)) bpy.ops.transform.rotate(value=(angle,), axis=rot_axis)  After copy-paste to blender console you will see the similar image:\n","date":"2012-04-11","permalink":"http://localhost:1313/blog/2012/04/11/blender-and-python-molecules-visualization/","tags":["blender","python"],"title":"Blender and Python molecules visualization"}]